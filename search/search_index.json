{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FairSample","text":"<p>A Python toolkit for handling imbalanced datasets with 14+ resampling techniques and 40+ complexity measures.</p>"},{"location":"#why-this-package","title":"Why This Package?","text":"<p>Most imbalanced learning packages only provide resampling techniques. This toolkit adds complexity measures to help you:</p> <ul> <li>Understand why your dataset is difficult</li> <li>Identify class overlap and boundary issues</li> <li>Choose the best technique for your data</li> <li>Measure improvement after resampling</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>14+ Resampling Techniques - Overlap-based, hybrid, and clustering methods</li> <li>40+ Complexity Measures - Feature, instance, structural, and multiresolution metrics</li> <li>Scikit-learn Compatible - Standard <code>fit_resample()</code> API</li> <li>Pandas Support - Works seamlessly with DataFrames</li> <li>No Forced Workflow - You control training and evaluation</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from fairsample import RFCL\nfrom fairsample.complexity import ComplexityMeasures\n\n# Check complexity\ncm = ComplexityMeasures(X, y)\nprint(f\"Overlap: {cm.analyze_overlap()['N3']:.4f}\")\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre>"},{"location":"#whats-included","title":"What's Included","text":""},{"location":"#resampling-techniques","title":"Resampling Techniques","text":"<ul> <li>Overlap-Based: RFCL, NUS, URNS, DeviOCSVM, FCMBoostOBU</li> <li>Hybrid: SVDDWSMOTE, ODBOT, EHSO</li> <li>Clustering: NBUS (4 variants), KMeansUndersampling (4 variants)</li> <li>Comprehensive: OSM</li> <li>Baselines: RandomOverSampler, RandomUnderSampler</li> </ul>"},{"location":"#complexity-measures","title":"Complexity Measures","text":"<ul> <li>Feature Overlap (6): F1, F1v, F2, F3, F4, Input Noise</li> <li>Instance Overlap (9): N3, N4, kDN, CM, R-value, D3, SI, Borderline, Degree of Overlap</li> <li>Structural (9): N1, N2, T1, DBC, LSC, Clust, NSG, ICSV, ONB</li> <li>Multiresolution (5): Purity, Neighbourhood Separability, MRCA, C1, C2</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<p>Installation Quick Start Examples</p>"},{"location":"#license","title":"License","text":"<p>MIT License - Free for commercial and personal use.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for considering contributing to FairSample!</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Report bugs and issues</li> <li>Suggest new features or techniques</li> <li>Improve documentation</li> <li>Submit bug fixes</li> <li>Add new resampling techniques</li> <li>Add new complexity measures</li> </ul>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li>Fork and clone the repository:</li> </ol> <pre><code>git clone https://github.com/yourusername/fairsample.git\ncd fairsample\n</code></pre> <ol> <li>Create a virtual environment:</li> </ol> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre> <ol> <li>Install in development mode:</li> </ol> <pre><code>pip install -e \".[dev]\"\n</code></pre> <ol> <li>Run tests:</li> </ol> <pre><code>pytest tests/\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Use type hints where possible</li> <li>Write docstrings for all public functions</li> <li>Keep functions focused and small</li> </ul>"},{"location":"contributing/#adding-a-new-technique","title":"Adding a New Technique","text":"<ol> <li>Create a new file in <code>fairsample/techniques/</code></li> <li>Implement the technique following scikit-learn's API:</li> </ol> <pre><code>from imblearn.base import BaseSampler\n\nclass MyTechnique(BaseSampler):\n    def __init__(self, param1=default1, random_state=None):\n        self.param1 = param1\n        self.random_state = random_state\n\n    def fit_resample(self, X, y):\n        # Your implementation\n        return X_resampled, y_resampled\n</code></pre> <ol> <li>Add to <code>fairsample/techniques/__init__.py</code></li> <li>Write tests in <code>tests/</code></li> <li>Update documentation</li> </ol>"},{"location":"contributing/#adding-a-complexity-measure","title":"Adding a Complexity Measure","text":"<ol> <li>Add method to <code>ComplexityMeasures</code> class in <code>fairsample/complexity/measures.py</code>:</li> </ol> <pre><code>def calculate_my_measure(self):\n    \"\"\"\n    Calculate my complexity measure.\n\n    Returns\n    -------\n    float\n        The complexity score.\n    \"\"\"\n    # Your implementation\n    return score\n</code></pre> <ol> <li>Add to appropriate category in <code>get_all_complexity_measures()</code></li> <li>Write tests</li> <li>Update documentation</li> </ol>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Write tests for all new code:</p> <pre><code>def test_my_technique():\n    from fairsample import MyTechnique\n\n    X, y = make_classification(n_samples=100, n_classes=2, weights=[0.9, 0.1])\n    sampler = MyTechnique()\n    X_resampled, y_resampled = sampler.fit_resample(X, y)\n\n    assert len(X_resampled) &gt; 0\n    assert len(X_resampled) == len(y_resampled)\n</code></pre> <p>Run tests:</p> <pre><code>pytest tests/ -v\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>Update documentation for any changes:</p> <ol> <li>Update docstrings in code</li> <li>Update relevant markdown files in <code>docs/</code></li> <li>Preview documentation:</li> </ol> <pre><code>mkdocs serve\n</code></pre> <ol> <li>Build documentation:</li> </ol> <pre><code>mkdocs build\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create a new branch:</li> </ol> <pre><code>git checkout -b feature/my-feature\n</code></pre> <ol> <li>Make your changes and commit:</li> </ol> <pre><code>git add .\ngit commit -m \"Add my feature\"\n</code></pre> <ol> <li>Push to your fork:</li> </ol> <pre><code>git push origin feature/my-feature\n</code></pre> <ol> <li> <p>Open a Pull Request on GitHub</p> </li> <li> <p>Ensure all tests pass and documentation is updated</p> </li> </ol>"},{"location":"contributing/#code-review","title":"Code Review","text":"<p>All submissions require review. We'll provide feedback and may request changes.</p>"},{"location":"contributing/#questions","title":"Questions?","text":"<p>Open an issue or start a discussion on GitHub.</p>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"api/complexity/","title":"Complexity API Reference","text":"<p>Complete API reference for complexity measures.</p>"},{"location":"api/complexity/#complexitymeasures","title":"ComplexityMeasures","text":"<p>Main class for calculating complexity measures.</p>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures","title":"<code>fairsample.complexity.ComplexityMeasures</code>","text":"<p>User-friendly wrapper for ComplexityMetrics with all complexity measures.</p> <p>This class provides easy access to all complexity measures with options to: - Get all measures at once - Get specific categories (feature/instance/structural/multiresolution) - Get specific measures by name</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Feature matrix</p> required <code>y</code> <code>array-like of shape (n_samples,)</code> <p>Target vector</p> required <code>distance_func</code> <code>str</code> <p>Distance function to use</p> <code>\"default\"</code> Example <p>cm = ComplexityMeasures(X, y)</p> Source code in <code>fairsample/complexity/measures.py</code> <pre><code>class ComplexityMeasures:\n    \"\"\"\n    User-friendly wrapper for ComplexityMetrics with all complexity measures.\n\n    This class provides easy access to all complexity measures with options to:\n    - Get all measures at once\n    - Get specific categories (feature/instance/structural/multiresolution)\n    - Get specific measures by name\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Feature matrix\n    y : array-like of shape (n_samples,)\n        Target vector\n    distance_func : str, default=\"default\"\n        Distance function to use\n\n    Example\n    -------\n    &gt;&gt;&gt; cm = ComplexityMeasures(X, y)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Get all measures\n    &gt;&gt;&gt; all_measures = cm.get_all_complexity_measures()\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Get specific category\n    &gt;&gt;&gt; feature_measures = cm.get_all_complexity_measures(measures='feature')\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Get specific measures\n    &gt;&gt;&gt; selected = cm.get_all_complexity_measures(measures=['N3', 'F1', 'N1'])\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Quick analysis\n    &gt;&gt;&gt; basic = cm.analyze_overlap()\n    \"\"\"\n\n    def __init__(self, X, y, distance_func=\"default\"):\n        \"\"\"Initialize complexity measures calculator.\"\"\"\n        self.metrics = ComplexityMetrics(X, y)\n        self.X = self.metrics.X\n        self.y = self.metrics.y\n        self.classes = self.metrics.classes\n        self.class_count = self.metrics.class_count\n        self.class_inxs = self.metrics.class_inxs\n        self.dist_matrix = self.metrics.dist_matrix\n\n    def get_all_complexity_measures(self, k=5, imb=False, measures='all'):\n        \"\"\"\n        Get all available complexity measures in a structured format.\n\n        Parameters\n        ----------\n        k : int, default=5\n            Number of neighbors for k-NN based measures\n        imb : bool, default=False\n            Whether to return class-specific values for imbalanced analysis\n        measures : str or list, default='all'\n            Which measures to calculate:\n            - 'all': All available measures\n            - 'basic': Essential measures (N3, N1, N2, F1, F2)\n            - 'feature': Only feature overlap measures\n            - 'instance': Only instance overlap measures\n            - 'structural': Only structural overlap measures\n            - 'multiresolution': Only multiresolution measures\n            - list: Specific measure names (e.g., ['N3', 'F1', 'N1'])\n\n        Returns\n        -------\n        results : dict\n            Structured dictionary with all complexity measures\n        \"\"\"\n        results = {\n            'dataset_info': {\n                'n_samples': len(self.X),\n                'n_features': self.X.shape[1],\n                'n_classes': len(self.classes),\n                'class_distribution': np.bincount(self.y).tolist(),\n                'imbalance_ratio': np.max(np.bincount(self.y)) / np.min(np.bincount(self.y))\n            },\n            'feature_overlap': {},\n            'instance_overlap': {},\n            'structural_overlap': {},\n            'multiresolution_overlap': {}\n        }\n\n        # Define measure categories\n        feature_measures = ['F1', 'F1v', 'F2', 'F3', 'F4', 'input_noise']\n        instance_measures = ['N3', 'N4', 'kDN', 'CM', 'R_value', 'D3_value', 'SI', \n                           'borderline', 'deg_overlap']\n        structural_measures = ['N1', 'N2', 'T1', 'DBC', 'LSC', 'Clust', 'NSG', \n                             'ICSV', 'ONB']\n        multiresolution_measures = ['purity', 'neighbourhood_separability', 'MRCA', \n                                   'C1', 'C2']\n\n        # Determine which measures to calculate\n        if measures == 'basic':\n            calc_measures = ['N3', 'N1', 'N2', 'F1', 'F2']\n        elif measures == 'all':\n            calc_measures = (feature_measures + instance_measures + \n                           structural_measures + multiresolution_measures)\n        elif measures == 'feature':\n            calc_measures = feature_measures\n        elif measures == 'instance':\n            calc_measures = instance_measures\n        elif measures == 'structural':\n            calc_measures = structural_measures\n        elif measures == 'multiresolution':\n            calc_measures = multiresolution_measures\n        elif isinstance(measures, list):\n            calc_measures = measures\n        else:\n            calc_measures = ['N3', 'N1', 'N2', 'F1', 'F2']\n\n        # Calculate measures\n        for measure_name in calc_measures:\n            try:\n                if measure_name == 'F1':\n                    results['feature_overlap']['F1'] = self.metrics.F1()\n                elif measure_name == 'F1v':\n                    results['feature_overlap']['F1v'] = self.metrics.F1v()\n                elif measure_name == 'F2':\n                    results['feature_overlap']['F2'] = self.metrics.F2(imb=imb)\n                elif measure_name == 'F3':\n                    results['feature_overlap']['F3'] = self.metrics.F3(imb=imb)\n                elif measure_name == 'F4':\n                    results['feature_overlap']['F4'] = self.metrics.F4(imb=imb)\n                elif measure_name == 'input_noise':\n                    results['feature_overlap']['input_noise'] = self.metrics.input_noise(imb=imb)\n\n                elif measure_name == 'N3':\n                    results['instance_overlap']['N3'] = self.metrics.N3(k=k, imb=imb)\n                elif measure_name == 'N4':\n                    results['instance_overlap']['N4'] = self.metrics.N4(k=k, imb=imb)\n                elif measure_name == 'kDN':\n                    results['instance_overlap']['kDN'] = self.metrics.kDN(k=k, imb=imb)\n                elif measure_name == 'CM':\n                    results['instance_overlap']['CM'] = self.metrics.CM(k=k, imb=imb)\n                elif measure_name == 'R_value':\n                    results['instance_overlap']['R_value'] = self.metrics.R_value(k=k, imb=imb)\n                elif measure_name == 'D3_value':\n                    results['instance_overlap']['D3'] = self.metrics.D3_value(k=k)\n                elif measure_name == 'SI':\n                    results['instance_overlap']['SI'] = self.metrics.SI(k=k, imb=imb)\n                elif measure_name == 'borderline':\n                    results['instance_overlap']['borderline'] = self.metrics.borderline(imb=imb)\n                elif measure_name == 'deg_overlap':\n                    results['instance_overlap']['deg_overlap'] = self.metrics.deg_overlap(k=k, imb=imb)\n\n                elif measure_name == 'N1':\n                    results['structural_overlap']['N1'] = self.metrics.N1(imb=imb)\n                elif measure_name == 'N2':\n                    results['structural_overlap']['N2'] = self.metrics.N2(imb=imb)\n                elif measure_name == 'T1':\n                    results['structural_overlap']['T1'] = self.metrics.T1(imb=imb)\n                elif measure_name == 'DBC':\n                    results['structural_overlap']['DBC'] = self.metrics.DBC(imb=imb)\n                elif measure_name == 'LSC':\n                    results['structural_overlap']['LSC'] = self.metrics.LSC(imb=imb)\n                elif measure_name == 'Clust':\n                    results['structural_overlap']['Clust'] = self.metrics.Clust(imb=imb)\n                elif measure_name == 'NSG':\n                    results['structural_overlap']['NSG'] = self.metrics.NSG(imb=imb)\n                elif measure_name == 'ICSV':\n                    results['structural_overlap']['ICSV'] = self.metrics.ICSV(imb=imb)\n                elif measure_name == 'ONB':\n                    results['structural_overlap']['ONB'] = self.metrics.ONB(imb=imb)\n\n                elif measure_name == 'purity':\n                    results['multiresolution_overlap']['purity'] = self.metrics.purity()\n                elif measure_name == 'neighbourhood_separability':\n                    results['multiresolution_overlap']['neighbourhood_separability'] = self.metrics.neighbourhood_separability()\n                elif measure_name == 'MRCA':\n                    results['multiresolution_overlap']['MRCA'] = self.metrics.MRCA()\n                elif measure_name == 'C1':\n                    results['multiresolution_overlap']['C1'] = self.metrics.C1(imb=imb)\n                elif measure_name == 'C2':\n                    results['multiresolution_overlap']['C2'] = self.metrics.C2(imb=imb)\n\n            except Exception as e:\n                if measures != 'all':  # Only warn if not calculating all\n                    print(f\"Warning: Could not calculate {measure_name}: {e}\")\n\n        return results\n\n    def analyze_overlap(self, measures='basic'):\n        \"\"\"\n        Quick overlap analysis using essential measures.\n\n        Parameters\n        ----------\n        measures : str, default='basic'\n            Level of analysis:\n            - 'basic': Essential measures (N3, N1, N2, F1, F2)\n            - 'standard': Common measures\n            - 'all': All available measures\n\n        Returns\n        -------\n        results : dict\n            Dictionary containing complexity measures\n        \"\"\"\n        if measures == 'basic':\n            results = {\n                'n_samples': len(self.X),\n                'n_features': self.X.shape[1],\n                'n_classes': len(self.classes),\n                'class_distribution': np.bincount(self.y).tolist(),\n                'imbalance_ratio': np.max(np.bincount(self.y)) / np.min(np.bincount(self.y)),\n                'N3': self._safe_calc(lambda: self.metrics.N3(k=1)),\n                'N1': self._safe_calc(lambda: self.metrics.N1()),\n                'N2': self._safe_calc(lambda: self.metrics.N2()),\n                'F1': self._safe_calc(lambda: np.mean(self.metrics.F1())),\n                'F2': self._safe_calc(lambda: np.mean(self.metrics.F2())),\n            }\n        elif measures == 'standard':\n            all_measures = self.get_all_complexity_measures(measures='all')\n            results = self._flatten_dict(all_measures)\n        elif measures == 'all':\n            all_measures = self.get_all_complexity_measures(measures='all')\n            results = all_measures\n        else:\n            results = self.analyze_overlap('basic')\n\n        return results\n\n    def _safe_calc(self, func):\n        \"\"\"Safely calculate a measure.\"\"\"\n        try:\n            return func()\n        except:\n            return None\n\n    def _flatten_dict(self, nested_dict):\n        \"\"\"Flatten nested dictionary.\"\"\"\n        flat = {}\n        for category, measures in nested_dict.items():\n            if isinstance(measures, dict):\n                for key, value in measures.items():\n                    if isinstance(value, (list, np.ndarray)):\n                        try:\n                            flat[key] = float(np.mean(value))\n                        except:\n                            flat[key] = value\n                    else:\n                        flat[key] = value\n            else:\n                flat[category] = measures\n        return flat\n</code></pre>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures--get-all-measures","title":"Get all measures","text":"<p>all_measures = cm.get_all_complexity_measures()</p>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures--get-specific-category","title":"Get specific category","text":"<p>feature_measures = cm.get_all_complexity_measures(measures='feature')</p>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures--get-specific-measures","title":"Get specific measures","text":"<p>selected = cm.get_all_complexity_measures(measures=['N3', 'F1', 'N1'])</p>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures--quick-analysis","title":"Quick analysis","text":"<p>basic = cm.analyze_overlap()</p>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures.__init__","title":"<code>__init__(X, y, distance_func='default')</code>","text":"<p>Initialize complexity measures calculator.</p> Source code in <code>fairsample/complexity/measures.py</code> <pre><code>def __init__(self, X, y, distance_func=\"default\"):\n    \"\"\"Initialize complexity measures calculator.\"\"\"\n    self.metrics = ComplexityMetrics(X, y)\n    self.X = self.metrics.X\n    self.y = self.metrics.y\n    self.classes = self.metrics.classes\n    self.class_count = self.metrics.class_count\n    self.class_inxs = self.metrics.class_inxs\n    self.dist_matrix = self.metrics.dist_matrix\n</code></pre>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures.analyze_overlap","title":"<code>analyze_overlap(measures='basic')</code>","text":"<p>Quick overlap analysis using essential measures.</p> <p>Parameters:</p> Name Type Description Default <code>measures</code> <code>str</code> <p>Level of analysis: - 'basic': Essential measures (N3, N1, N2, F1, F2) - 'standard': Common measures - 'all': All available measures</p> <code>'basic'</code> <p>Returns:</p> Name Type Description <code>results</code> <code>dict</code> <p>Dictionary containing complexity measures</p> Source code in <code>fairsample/complexity/measures.py</code> <pre><code>def analyze_overlap(self, measures='basic'):\n    \"\"\"\n    Quick overlap analysis using essential measures.\n\n    Parameters\n    ----------\n    measures : str, default='basic'\n        Level of analysis:\n        - 'basic': Essential measures (N3, N1, N2, F1, F2)\n        - 'standard': Common measures\n        - 'all': All available measures\n\n    Returns\n    -------\n    results : dict\n        Dictionary containing complexity measures\n    \"\"\"\n    if measures == 'basic':\n        results = {\n            'n_samples': len(self.X),\n            'n_features': self.X.shape[1],\n            'n_classes': len(self.classes),\n            'class_distribution': np.bincount(self.y).tolist(),\n            'imbalance_ratio': np.max(np.bincount(self.y)) / np.min(np.bincount(self.y)),\n            'N3': self._safe_calc(lambda: self.metrics.N3(k=1)),\n            'N1': self._safe_calc(lambda: self.metrics.N1()),\n            'N2': self._safe_calc(lambda: self.metrics.N2()),\n            'F1': self._safe_calc(lambda: np.mean(self.metrics.F1())),\n            'F2': self._safe_calc(lambda: np.mean(self.metrics.F2())),\n        }\n    elif measures == 'standard':\n        all_measures = self.get_all_complexity_measures(measures='all')\n        results = self._flatten_dict(all_measures)\n    elif measures == 'all':\n        all_measures = self.get_all_complexity_measures(measures='all')\n        results = all_measures\n    else:\n        results = self.analyze_overlap('basic')\n\n    return results\n</code></pre>"},{"location":"api/complexity/#fairsample.complexity.ComplexityMeasures.get_all_complexity_measures","title":"<code>get_all_complexity_measures(k=5, imb=False, measures='all')</code>","text":"<p>Get all available complexity measures in a structured format.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Number of neighbors for k-NN based measures</p> <code>5</code> <code>imb</code> <code>bool</code> <p>Whether to return class-specific values for imbalanced analysis</p> <code>False</code> <code>measures</code> <code>str or list</code> <p>Which measures to calculate: - 'all': All available measures - 'basic': Essential measures (N3, N1, N2, F1, F2) - 'feature': Only feature overlap measures - 'instance': Only instance overlap measures - 'structural': Only structural overlap measures - 'multiresolution': Only multiresolution measures - list: Specific measure names (e.g., ['N3', 'F1', 'N1'])</p> <code>'all'</code> <p>Returns:</p> Name Type Description <code>results</code> <code>dict</code> <p>Structured dictionary with all complexity measures</p> Source code in <code>fairsample/complexity/measures.py</code> <pre><code>def get_all_complexity_measures(self, k=5, imb=False, measures='all'):\n    \"\"\"\n    Get all available complexity measures in a structured format.\n\n    Parameters\n    ----------\n    k : int, default=5\n        Number of neighbors for k-NN based measures\n    imb : bool, default=False\n        Whether to return class-specific values for imbalanced analysis\n    measures : str or list, default='all'\n        Which measures to calculate:\n        - 'all': All available measures\n        - 'basic': Essential measures (N3, N1, N2, F1, F2)\n        - 'feature': Only feature overlap measures\n        - 'instance': Only instance overlap measures\n        - 'structural': Only structural overlap measures\n        - 'multiresolution': Only multiresolution measures\n        - list: Specific measure names (e.g., ['N3', 'F1', 'N1'])\n\n    Returns\n    -------\n    results : dict\n        Structured dictionary with all complexity measures\n    \"\"\"\n    results = {\n        'dataset_info': {\n            'n_samples': len(self.X),\n            'n_features': self.X.shape[1],\n            'n_classes': len(self.classes),\n            'class_distribution': np.bincount(self.y).tolist(),\n            'imbalance_ratio': np.max(np.bincount(self.y)) / np.min(np.bincount(self.y))\n        },\n        'feature_overlap': {},\n        'instance_overlap': {},\n        'structural_overlap': {},\n        'multiresolution_overlap': {}\n    }\n\n    # Define measure categories\n    feature_measures = ['F1', 'F1v', 'F2', 'F3', 'F4', 'input_noise']\n    instance_measures = ['N3', 'N4', 'kDN', 'CM', 'R_value', 'D3_value', 'SI', \n                       'borderline', 'deg_overlap']\n    structural_measures = ['N1', 'N2', 'T1', 'DBC', 'LSC', 'Clust', 'NSG', \n                         'ICSV', 'ONB']\n    multiresolution_measures = ['purity', 'neighbourhood_separability', 'MRCA', \n                               'C1', 'C2']\n\n    # Determine which measures to calculate\n    if measures == 'basic':\n        calc_measures = ['N3', 'N1', 'N2', 'F1', 'F2']\n    elif measures == 'all':\n        calc_measures = (feature_measures + instance_measures + \n                       structural_measures + multiresolution_measures)\n    elif measures == 'feature':\n        calc_measures = feature_measures\n    elif measures == 'instance':\n        calc_measures = instance_measures\n    elif measures == 'structural':\n        calc_measures = structural_measures\n    elif measures == 'multiresolution':\n        calc_measures = multiresolution_measures\n    elif isinstance(measures, list):\n        calc_measures = measures\n    else:\n        calc_measures = ['N3', 'N1', 'N2', 'F1', 'F2']\n\n    # Calculate measures\n    for measure_name in calc_measures:\n        try:\n            if measure_name == 'F1':\n                results['feature_overlap']['F1'] = self.metrics.F1()\n            elif measure_name == 'F1v':\n                results['feature_overlap']['F1v'] = self.metrics.F1v()\n            elif measure_name == 'F2':\n                results['feature_overlap']['F2'] = self.metrics.F2(imb=imb)\n            elif measure_name == 'F3':\n                results['feature_overlap']['F3'] = self.metrics.F3(imb=imb)\n            elif measure_name == 'F4':\n                results['feature_overlap']['F4'] = self.metrics.F4(imb=imb)\n            elif measure_name == 'input_noise':\n                results['feature_overlap']['input_noise'] = self.metrics.input_noise(imb=imb)\n\n            elif measure_name == 'N3':\n                results['instance_overlap']['N3'] = self.metrics.N3(k=k, imb=imb)\n            elif measure_name == 'N4':\n                results['instance_overlap']['N4'] = self.metrics.N4(k=k, imb=imb)\n            elif measure_name == 'kDN':\n                results['instance_overlap']['kDN'] = self.metrics.kDN(k=k, imb=imb)\n            elif measure_name == 'CM':\n                results['instance_overlap']['CM'] = self.metrics.CM(k=k, imb=imb)\n            elif measure_name == 'R_value':\n                results['instance_overlap']['R_value'] = self.metrics.R_value(k=k, imb=imb)\n            elif measure_name == 'D3_value':\n                results['instance_overlap']['D3'] = self.metrics.D3_value(k=k)\n            elif measure_name == 'SI':\n                results['instance_overlap']['SI'] = self.metrics.SI(k=k, imb=imb)\n            elif measure_name == 'borderline':\n                results['instance_overlap']['borderline'] = self.metrics.borderline(imb=imb)\n            elif measure_name == 'deg_overlap':\n                results['instance_overlap']['deg_overlap'] = self.metrics.deg_overlap(k=k, imb=imb)\n\n            elif measure_name == 'N1':\n                results['structural_overlap']['N1'] = self.metrics.N1(imb=imb)\n            elif measure_name == 'N2':\n                results['structural_overlap']['N2'] = self.metrics.N2(imb=imb)\n            elif measure_name == 'T1':\n                results['structural_overlap']['T1'] = self.metrics.T1(imb=imb)\n            elif measure_name == 'DBC':\n                results['structural_overlap']['DBC'] = self.metrics.DBC(imb=imb)\n            elif measure_name == 'LSC':\n                results['structural_overlap']['LSC'] = self.metrics.LSC(imb=imb)\n            elif measure_name == 'Clust':\n                results['structural_overlap']['Clust'] = self.metrics.Clust(imb=imb)\n            elif measure_name == 'NSG':\n                results['structural_overlap']['NSG'] = self.metrics.NSG(imb=imb)\n            elif measure_name == 'ICSV':\n                results['structural_overlap']['ICSV'] = self.metrics.ICSV(imb=imb)\n            elif measure_name == 'ONB':\n                results['structural_overlap']['ONB'] = self.metrics.ONB(imb=imb)\n\n            elif measure_name == 'purity':\n                results['multiresolution_overlap']['purity'] = self.metrics.purity()\n            elif measure_name == 'neighbourhood_separability':\n                results['multiresolution_overlap']['neighbourhood_separability'] = self.metrics.neighbourhood_separability()\n            elif measure_name == 'MRCA':\n                results['multiresolution_overlap']['MRCA'] = self.metrics.MRCA()\n            elif measure_name == 'C1':\n                results['multiresolution_overlap']['C1'] = self.metrics.C1(imb=imb)\n            elif measure_name == 'C2':\n                results['multiresolution_overlap']['C2'] = self.metrics.C2(imb=imb)\n\n        except Exception as e:\n            if measures != 'all':  # Only warn if not calculating all\n                print(f\"Warning: Could not calculate {measure_name}: {e}\")\n\n    return results\n</code></pre>"},{"location":"api/complexity/#usage","title":"Usage","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\n# Create analyzer\ncm = ComplexityMeasures(X, y)\n\n# Get basic overlap measures\nbasic = cm.analyze_overlap()\n\n# Get all measures\nall_measures = cm.get_all_complexity_measures(measures='all')\n\n# Get specific category\nfeature = cm.get_all_complexity_measures(measures='feature')\n\n# Get specific measures\nselected = cm.get_all_complexity_measures(measures=['N3', 'F1'])\n</code></pre>"},{"location":"api/complexity/#individual-measures","title":"Individual Measures","text":""},{"location":"api/complexity/#feature-overlap","title":"Feature Overlap","text":"<pre><code># F1 - Maximum Fisher's Discriminant Ratio\nf1 = cm.calculate_F1()\n\n# F1v - Directional-vector maximum Fisher's discriminant ratio\nf1v = cm.calculate_F1v()\n\n# F2 - Volume of overlapping region\nf2 = cm.calculate_F2()\n\n# F3 - Maximum individual feature efficiency\nf3 = cm.calculate_F3()\n\n# F4 - Collective feature efficiency\nf4 = cm.calculate_F4()\n\n# Input Noise\nnoise = cm.calculate_input_noise()\n</code></pre>"},{"location":"api/complexity/#instance-overlap","title":"Instance Overlap","text":"<pre><code># N3 - Error rate of nearest neighbor\nn3 = cm.calculate_N3()\n\n# N4 - Non-linearity of nearest neighbor\nn4 = cm.calculate_N4()\n\n# kDN - k-Disagreeing neighbors\nkdn = cm.calculate_kDN(k=5)\n\n# CM - Class imbalance metric\ncm_score = cm.calculate_CM()\n\n# R-value - Overlap region size\nr_value = cm.calculate_R_value()\n\n# D3 - Disjunct class percentage\nd3 = cm.calculate_D3()\n\n# SI - Silhouette index\nsi = cm.calculate_SI()\n\n# Borderline - Borderline instance ratio\nborderline = cm.calculate_borderline()\n\n# Degree of overlap\noverlap = cm.calculate_degree_of_overlap()\n</code></pre>"},{"location":"api/complexity/#structural","title":"Structural","text":"<pre><code># N1 - Fraction of borderline points\nn1 = cm.calculate_N1()\n\n# N2 - Ratio of intra/extra class nearest neighbor distance\nn2 = cm.calculate_N2()\n\n# T1 - Fraction of hyperspheres covering data\nt1 = cm.calculate_T1()\n\n# DBC - Distance-based complexity\ndbc = cm.calculate_DBC()\n\n# LSC - Local set cardinality\nlsc = cm.calculate_LSC()\n\n# Clust - Clustering measure\nclust = cm.calculate_Clust()\n\n# NSG - Number of spanning graphs\nnsg = cm.calculate_NSG()\n\n# ICSV - Inter-class to intra-class similarity variance\nicsv = cm.calculate_ICSV()\n\n# ONB - Overlap of neighborhoods between classes\nonb = cm.calculate_ONB()\n</code></pre>"},{"location":"api/complexity/#multiresolution","title":"Multiresolution","text":"<pre><code># Purity\npurity = cm.calculate_purity()\n\n# Neighbourhood Separability\nns = cm.calculate_neighbourhood_separability()\n\n# MRCA - Multiresolution complexity analysis\nmrca = cm.calculate_MRCA()\n\n# C1 - Entropy of class proportions\nc1 = cm.calculate_C1()\n\n# C2 - Imbalance ratio\nc2 = cm.calculate_C2()\n</code></pre>"},{"location":"api/complexity/#utility-functions","title":"Utility Functions","text":""},{"location":"api/complexity/#compare_pre_post_overlap","title":"compare_pre_post_overlap","text":"<p>Compare complexity before and after resampling.</p> <pre><code>from fairsample.complexity import compare_pre_post_overlap\n\ncomparison = compare_pre_post_overlap(\n    X_before, y_before,\n    X_after, y_after,\n    measures='basic'\n)\n\nprint(comparison['before'])\nprint(comparison['after'])\nprint(comparison['improvements'])\n</code></pre>"},{"location":"api/complexity/#measure-categories","title":"Measure Categories","text":"<p>Use these strings with <code>get_all_complexity_measures()</code>:</p> <ul> <li><code>'all'</code> - All 40+ measures</li> <li><code>'basic'</code> - Quick subset (N3, F1, N1, T1, imbalance_ratio)</li> <li><code>'feature'</code> - Feature overlap measures</li> <li><code>'instance'</code> - Instance overlap measures</li> <li><code>'structural'</code> - Structural measures</li> <li><code>'multiresolution'</code> - Multiresolution measures</li> <li><code>['N3', 'F1', ...]</code> - List of specific measures</li> </ul>"},{"location":"api/techniques/","title":"Techniques API Reference","text":"<p>Complete API reference for all resampling techniques.</p>"},{"location":"api/techniques/#base-api","title":"Base API","text":"<p>All techniques follow scikit-learn's API:</p> <pre><code>sampler = Technique(parameters)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre>"},{"location":"api/techniques/#overlap-based-undersampling","title":"Overlap-Based Undersampling","text":""},{"location":"api/techniques/#rfcl","title":"RFCL","text":""},{"location":"api/techniques/#fairsample.techniques.RFCL","title":"<code>fairsample.techniques.RFCL</code>","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Random Forest Cleaning Rule (RFCL).</p> <p>This technique uses Random Forest to identify and remove noisy/overlapping majority class samples that are likely to be misclassified.</p> <p>Parameters:</p> Name Type Description Default <code>n_estimators</code> <code>int</code> <p>Number of trees in the random forest</p> <code>100</code> <code>random_state</code> <code>int</code> <p>Random state for reproducibility</p> <code>None</code> <code>cv</code> <code>int</code> <p>Number of cross-validation folds</p> <code>3</code> Source code in <code>fairsample/techniques/rfcl.py</code> <pre><code>class RFCL(BaseSampler):\n    \"\"\"\n    Random Forest Cleaning Rule (RFCL).\n\n    This technique uses Random Forest to identify and remove noisy/overlapping\n    majority class samples that are likely to be misclassified.\n\n    Parameters\n    ----------\n    n_estimators : int, default=100\n        Number of trees in the random forest\n    random_state : int, default=None\n        Random state for reproducibility\n    cv : int, default=3\n        Number of cross-validation folds\n    \"\"\"\n\n    def __init__(self, n_estimators=100, random_state=None, cv=3):\n        super().__init__(random_state=random_state)\n        self.n_estimators = n_estimators\n        self.cv = cv\n        self._sampling_type = 'undersampling'\n\n    def fit_resample(self, X, y):\n        \"\"\"\n        Resample the dataset using RFCL.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data\n        y : array-like of shape (n_samples,)\n            Target values\n\n        Returns\n        -------\n        X_resampled : array-like\n            Resampled training data\n        y_resampled : array-like\n            Resampled target values\n        \"\"\"\n        X, y = self._validate_input(X, y)\n\n        # Get minority and majority class indices\n        minority_indices, majority_indices, minority_class, majority_class = \\\n            self._get_minority_majority_indices(y)\n\n        # If dataset is already balanced or minority is larger, return as is\n        if len(minority_indices) &gt;= len(majority_indices):\n            return X.copy(), y.copy()\n\n        # Create Random Forest classifier\n        rf = RandomForestClassifier(\n            n_estimators=self.n_estimators,\n            random_state=self.random_state\n        )\n\n        # Get cross-validation predictions\n        try:\n            y_pred = cross_val_predict(rf, X, y, cv=self.cv)\n        except:\n            # Fallback: fit on full data and predict\n            rf.fit(X, y)\n            y_pred = rf.predict(X)\n\n        # Identify correctly classified majority samples\n        majority_mask = y == majority_class\n        correctly_classified_majority = majority_indices[\n            y_pred[majority_indices] == y[majority_indices]\n        ]\n\n        # Keep all minority samples and correctly classified majority samples\n        keep_indices = np.concatenate([minority_indices, correctly_classified_majority])\n\n        # If we removed too many samples, keep some randomly\n        if len(correctly_classified_majority) &lt; len(minority_indices):\n            # Keep at least as many majority samples as minority samples\n            n_additional = len(minority_indices) - len(correctly_classified_majority)\n            incorrectly_classified_majority = majority_indices[\n                y_pred[majority_indices] != y[majority_indices]\n            ]\n\n            if len(incorrectly_classified_majority) &gt; 0:\n                np.random.seed(self.random_state)\n                additional_indices = np.random.choice(\n                    incorrectly_classified_majority,\n                    size=min(n_additional, len(incorrectly_classified_majority)),\n                    replace=False\n                )\n                keep_indices = np.concatenate([keep_indices, additional_indices])\n\n        # Sort indices to maintain order\n        keep_indices = np.sort(keep_indices)\n\n        return X[keep_indices], y[keep_indices]\n</code></pre>"},{"location":"api/techniques/#fairsample.techniques.RFCL.fit_resample","title":"<code>fit_resample(X, y)</code>","text":"<p>Resample the dataset using RFCL.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Training data</p> required <code>y</code> <code>array-like of shape (n_samples,)</code> <p>Target values</p> required <p>Returns:</p> Name Type Description <code>X_resampled</code> <code>array - like</code> <p>Resampled training data</p> <code>y_resampled</code> <code>array - like</code> <p>Resampled target values</p> Source code in <code>fairsample/techniques/rfcl.py</code> <pre><code>def fit_resample(self, X, y):\n    \"\"\"\n    Resample the dataset using RFCL.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Training data\n    y : array-like of shape (n_samples,)\n        Target values\n\n    Returns\n    -------\n    X_resampled : array-like\n        Resampled training data\n    y_resampled : array-like\n        Resampled target values\n    \"\"\"\n    X, y = self._validate_input(X, y)\n\n    # Get minority and majority class indices\n    minority_indices, majority_indices, minority_class, majority_class = \\\n        self._get_minority_majority_indices(y)\n\n    # If dataset is already balanced or minority is larger, return as is\n    if len(minority_indices) &gt;= len(majority_indices):\n        return X.copy(), y.copy()\n\n    # Create Random Forest classifier\n    rf = RandomForestClassifier(\n        n_estimators=self.n_estimators,\n        random_state=self.random_state\n    )\n\n    # Get cross-validation predictions\n    try:\n        y_pred = cross_val_predict(rf, X, y, cv=self.cv)\n    except:\n        # Fallback: fit on full data and predict\n        rf.fit(X, y)\n        y_pred = rf.predict(X)\n\n    # Identify correctly classified majority samples\n    majority_mask = y == majority_class\n    correctly_classified_majority = majority_indices[\n        y_pred[majority_indices] == y[majority_indices]\n    ]\n\n    # Keep all minority samples and correctly classified majority samples\n    keep_indices = np.concatenate([minority_indices, correctly_classified_majority])\n\n    # If we removed too many samples, keep some randomly\n    if len(correctly_classified_majority) &lt; len(minority_indices):\n        # Keep at least as many majority samples as minority samples\n        n_additional = len(minority_indices) - len(correctly_classified_majority)\n        incorrectly_classified_majority = majority_indices[\n            y_pred[majority_indices] != y[majority_indices]\n        ]\n\n        if len(incorrectly_classified_majority) &gt; 0:\n            np.random.seed(self.random_state)\n            additional_indices = np.random.choice(\n                incorrectly_classified_majority,\n                size=min(n_additional, len(incorrectly_classified_majority)),\n                replace=False\n            )\n            keep_indices = np.concatenate([keep_indices, additional_indices])\n\n    # Sort indices to maintain order\n    keep_indices = np.sort(keep_indices)\n\n    return X[keep_indices], y[keep_indices]\n</code></pre>"},{"location":"api/techniques/#nus","title":"NUS","text":""},{"location":"api/techniques/#fairsample.techniques.NUS","title":"<code>fairsample.techniques.NUS</code>","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Neighbourhood-based Under-Sampling (NUS).</p> <p>This technique removes majority class samples that are in the neighborhood of minority class samples, helping to reduce class overlap.</p> <p>Parameters:</p> Name Type Description Default <code>n_neighbors</code> <code>int</code> <p>Number of neighbors to consider</p> <code>3</code> <code>random_state</code> <code>int</code> <p>Random state for reproducibility</p> <code>None</code> Source code in <code>fairsample/techniques/nus.py</code> <pre><code>class NUS(BaseSampler):\n    \"\"\"\n    Neighbourhood-based Under-Sampling (NUS).\n\n    This technique removes majority class samples that are in the neighborhood\n    of minority class samples, helping to reduce class overlap.\n\n    Parameters\n    ----------\n    n_neighbors : int, default=3\n        Number of neighbors to consider\n    random_state : int, default=None\n        Random state for reproducibility\n    \"\"\"\n\n    def __init__(self, n_neighbors=3, random_state=None):\n        super().__init__(random_state=random_state)\n        self.n_neighbors = n_neighbors\n        self._sampling_type = 'undersampling'\n\n    def fit_resample(self, X, y):\n        \"\"\"\n        Resample the dataset using NUS.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data\n        y : array-like of shape (n_samples,)\n            Target values\n\n        Returns\n        -------\n        X_resampled : array-like\n            Resampled training data\n        y_resampled : array-like\n            Resampled target values\n        \"\"\"\n        X, y = self._validate_input(X, y)\n\n        # Get minority and majority class indices\n        minority_indices, majority_indices, minority_class, majority_class = \\\n            self._get_minority_majority_indices(y)\n\n        # If dataset is already balanced or minority is larger, return as is\n        if len(minority_indices) &gt;= len(majority_indices):\n            return X.copy(), y.copy()\n\n        # Fit k-NN on minority samples\n        X_minority = X[minority_indices]\n\n        # Adjust n_neighbors if we have fewer minority samples\n        k = min(self.n_neighbors, len(X_minority) - 1)\n        if k &lt;= 0:\n            return X.copy(), y.copy()\n\n        knn = NearestNeighbors(n_neighbors=k + 1)  # +1 because it includes the point itself\n        knn.fit(X_minority)\n\n        # Find majority samples that are neighbors of minority samples\n        X_majority = X[majority_indices]\n        distances, indices = knn.kneighbors(X_majority)\n\n        # Remove majority samples that are too close to minority samples\n        # Use median distance as threshold\n        median_distance = np.median(distances[:, 1])  # Skip first column (self)\n\n        # Keep majority samples that are far enough from minority samples\n        keep_majority_mask = distances[:, 1] &gt; median_distance\n        keep_majority_indices = majority_indices[keep_majority_mask]\n\n        # Ensure we keep at least as many majority samples as minority samples\n        if len(keep_majority_indices) &lt; len(minority_indices):\n            # If we removed too many, keep some of the closest ones\n            n_additional = len(minority_indices) - len(keep_majority_indices)\n            removed_indices = majority_indices[~keep_majority_mask]\n\n            if len(removed_indices) &gt; 0:\n                # Sort by distance and keep the farthest ones among the removed\n                removed_distances = distances[~keep_majority_mask, 1]\n                sorted_indices = np.argsort(removed_distances)[::-1]  # Descending order\n                additional_indices = removed_indices[sorted_indices[:n_additional]]\n                keep_majority_indices = np.concatenate([keep_majority_indices, additional_indices])\n\n        # Combine minority and selected majority samples\n        keep_indices = np.concatenate([minority_indices, keep_majority_indices])\n        keep_indices = np.sort(keep_indices)\n\n        return X[keep_indices], y[keep_indices]\n</code></pre>"},{"location":"api/techniques/#fairsample.techniques.NUS.fit_resample","title":"<code>fit_resample(X, y)</code>","text":"<p>Resample the dataset using NUS.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Training data</p> required <code>y</code> <code>array-like of shape (n_samples,)</code> <p>Target values</p> required <p>Returns:</p> Name Type Description <code>X_resampled</code> <code>array - like</code> <p>Resampled training data</p> <code>y_resampled</code> <code>array - like</code> <p>Resampled target values</p> Source code in <code>fairsample/techniques/nus.py</code> <pre><code>def fit_resample(self, X, y):\n    \"\"\"\n    Resample the dataset using NUS.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Training data\n    y : array-like of shape (n_samples,)\n        Target values\n\n    Returns\n    -------\n    X_resampled : array-like\n        Resampled training data\n    y_resampled : array-like\n        Resampled target values\n    \"\"\"\n    X, y = self._validate_input(X, y)\n\n    # Get minority and majority class indices\n    minority_indices, majority_indices, minority_class, majority_class = \\\n        self._get_minority_majority_indices(y)\n\n    # If dataset is already balanced or minority is larger, return as is\n    if len(minority_indices) &gt;= len(majority_indices):\n        return X.copy(), y.copy()\n\n    # Fit k-NN on minority samples\n    X_minority = X[minority_indices]\n\n    # Adjust n_neighbors if we have fewer minority samples\n    k = min(self.n_neighbors, len(X_minority) - 1)\n    if k &lt;= 0:\n        return X.copy(), y.copy()\n\n    knn = NearestNeighbors(n_neighbors=k + 1)  # +1 because it includes the point itself\n    knn.fit(X_minority)\n\n    # Find majority samples that are neighbors of minority samples\n    X_majority = X[majority_indices]\n    distances, indices = knn.kneighbors(X_majority)\n\n    # Remove majority samples that are too close to minority samples\n    # Use median distance as threshold\n    median_distance = np.median(distances[:, 1])  # Skip first column (self)\n\n    # Keep majority samples that are far enough from minority samples\n    keep_majority_mask = distances[:, 1] &gt; median_distance\n    keep_majority_indices = majority_indices[keep_majority_mask]\n\n    # Ensure we keep at least as many majority samples as minority samples\n    if len(keep_majority_indices) &lt; len(minority_indices):\n        # If we removed too many, keep some of the closest ones\n        n_additional = len(minority_indices) - len(keep_majority_indices)\n        removed_indices = majority_indices[~keep_majority_mask]\n\n        if len(removed_indices) &gt; 0:\n            # Sort by distance and keep the farthest ones among the removed\n            removed_distances = distances[~keep_majority_mask, 1]\n            sorted_indices = np.argsort(removed_distances)[::-1]  # Descending order\n            additional_indices = removed_indices[sorted_indices[:n_additional]]\n            keep_majority_indices = np.concatenate([keep_majority_indices, additional_indices])\n\n    # Combine minority and selected majority samples\n    keep_indices = np.concatenate([minority_indices, keep_majority_indices])\n    keep_indices = np.sort(keep_indices)\n\n    return X[keep_indices], y[keep_indices]\n</code></pre>"},{"location":"api/techniques/#urns","title":"URNS","text":""},{"location":"api/techniques/#fairsample.techniques.URNS","title":"<code>fairsample.techniques.URNS</code>","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Undersampling based on Recursive Neighbourhood Search (URNS).</p> <p>This technique recursively removes majority class samples that are in dense regions and close to the decision boundary.</p> <p>Parameters:</p> Name Type Description Default <code>n_neighbors</code> <code>int</code> <p>Number of neighbors to consider</p> <code>5</code> <code>random_state</code> <code>int</code> <p>Random state for reproducibility</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of recursive iterations</p> <code>10</code> Source code in <code>fairsample/techniques/urns.py</code> <pre><code>class URNS(BaseSampler):\n    \"\"\"\n    Undersampling based on Recursive Neighbourhood Search (URNS).\n\n    This technique recursively removes majority class samples that are\n    in dense regions and close to the decision boundary.\n\n    Parameters\n    ----------\n    n_neighbors : int, default=5\n        Number of neighbors to consider\n    random_state : int, default=None\n        Random state for reproducibility\n    max_iterations : int, default=10\n        Maximum number of recursive iterations\n    \"\"\"\n\n    def __init__(self, n_neighbors=5, random_state=None, max_iterations=10):\n        super().__init__(random_state=random_state)\n        self.n_neighbors = n_neighbors\n        self.max_iterations = max_iterations\n        self._sampling_type = 'undersampling'\n\n    def fit_resample(self, X, y):\n        \"\"\"\n        Resample the dataset using URNS.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data\n        y : array-like of shape (n_samples,)\n            Target values\n\n        Returns\n        -------\n        X_resampled : array-like\n            Resampled training data\n        y_resampled : array-like\n            Resampled target values\n        \"\"\"\n        X, y = self._validate_input(X, y)\n\n        # Get minority and majority class indices\n        minority_indices, majority_indices, minority_class, majority_class = \\\n            self._get_minority_majority_indices(y)\n\n        # If dataset is already balanced or minority is larger, return as is\n        if len(minority_indices) &gt;= len(majority_indices):\n            return X.copy(), y.copy()\n\n        # Start with all samples\n        current_indices = np.arange(len(X))\n        target_majority_size = len(minority_indices)\n\n        for iteration in range(self.max_iterations):\n            # Get current majority indices\n            current_y = y[current_indices]\n            current_majority_mask = current_y == majority_class\n            current_majority_indices = current_indices[current_majority_mask]\n\n            # If we've reached the target size, stop\n            if len(current_majority_indices) &lt;= target_majority_size:\n                break\n\n            # Fit k-NN on current data\n            X_current = X[current_indices]\n            k = min(self.n_neighbors, len(X_current) - 1)\n            if k &lt;= 0:\n                break\n\n            knn = NearestNeighbors(n_neighbors=k + 1)\n            knn.fit(X_current)\n\n            # Find neighbors for each sample\n            distances, indices = knn.kneighbors(X_current)\n\n            # Calculate neighborhood purity for majority samples\n            majority_scores = []\n            current_majority_local_indices = np.where(current_majority_mask)[0]\n\n            for local_idx in current_majority_local_indices:\n                # Get neighbors (excluding self)\n                neighbor_indices = indices[local_idx, 1:]\n                neighbor_labels = current_y[neighbor_indices]\n\n                # Calculate purity (fraction of majority class neighbors)\n                purity = np.sum(neighbor_labels == majority_class) / len(neighbor_labels)\n                majority_scores.append((local_idx, purity))\n\n            if not majority_scores:\n                break\n\n            # Sort by purity (highest first) and remove samples with highest purity\n            majority_scores.sort(key=lambda x: x[1], reverse=True)\n\n            # Remove a fraction of the most pure majority samples\n            n_to_remove = min(\n                len(current_majority_indices) - target_majority_size,\n                max(1, len(majority_scores) // 4)  # Remove 25% at most\n            )\n\n            indices_to_remove = [score[0] for score in majority_scores[:n_to_remove]]\n            global_indices_to_remove = current_indices[indices_to_remove]\n\n            # Update current indices\n            current_indices = np.setdiff1d(current_indices, global_indices_to_remove)\n\n        return X[current_indices], y[current_indices]\n</code></pre>"},{"location":"api/techniques/#fairsample.techniques.URNS.fit_resample","title":"<code>fit_resample(X, y)</code>","text":"<p>Resample the dataset using URNS.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Training data</p> required <code>y</code> <code>array-like of shape (n_samples,)</code> <p>Target values</p> required <p>Returns:</p> Name Type Description <code>X_resampled</code> <code>array - like</code> <p>Resampled training data</p> <code>y_resampled</code> <code>array - like</code> <p>Resampled target values</p> Source code in <code>fairsample/techniques/urns.py</code> <pre><code>def fit_resample(self, X, y):\n    \"\"\"\n    Resample the dataset using URNS.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Training data\n    y : array-like of shape (n_samples,)\n        Target values\n\n    Returns\n    -------\n    X_resampled : array-like\n        Resampled training data\n    y_resampled : array-like\n        Resampled target values\n    \"\"\"\n    X, y = self._validate_input(X, y)\n\n    # Get minority and majority class indices\n    minority_indices, majority_indices, minority_class, majority_class = \\\n        self._get_minority_majority_indices(y)\n\n    # If dataset is already balanced or minority is larger, return as is\n    if len(minority_indices) &gt;= len(majority_indices):\n        return X.copy(), y.copy()\n\n    # Start with all samples\n    current_indices = np.arange(len(X))\n    target_majority_size = len(minority_indices)\n\n    for iteration in range(self.max_iterations):\n        # Get current majority indices\n        current_y = y[current_indices]\n        current_majority_mask = current_y == majority_class\n        current_majority_indices = current_indices[current_majority_mask]\n\n        # If we've reached the target size, stop\n        if len(current_majority_indices) &lt;= target_majority_size:\n            break\n\n        # Fit k-NN on current data\n        X_current = X[current_indices]\n        k = min(self.n_neighbors, len(X_current) - 1)\n        if k &lt;= 0:\n            break\n\n        knn = NearestNeighbors(n_neighbors=k + 1)\n        knn.fit(X_current)\n\n        # Find neighbors for each sample\n        distances, indices = knn.kneighbors(X_current)\n\n        # Calculate neighborhood purity for majority samples\n        majority_scores = []\n        current_majority_local_indices = np.where(current_majority_mask)[0]\n\n        for local_idx in current_majority_local_indices:\n            # Get neighbors (excluding self)\n            neighbor_indices = indices[local_idx, 1:]\n            neighbor_labels = current_y[neighbor_indices]\n\n            # Calculate purity (fraction of majority class neighbors)\n            purity = np.sum(neighbor_labels == majority_class) / len(neighbor_labels)\n            majority_scores.append((local_idx, purity))\n\n        if not majority_scores:\n            break\n\n        # Sort by purity (highest first) and remove samples with highest purity\n        majority_scores.sort(key=lambda x: x[1], reverse=True)\n\n        # Remove a fraction of the most pure majority samples\n        n_to_remove = min(\n            len(current_majority_indices) - target_majority_size,\n            max(1, len(majority_scores) // 4)  # Remove 25% at most\n        )\n\n        indices_to_remove = [score[0] for score in majority_scores[:n_to_remove]]\n        global_indices_to_remove = current_indices[indices_to_remove]\n\n        # Update current indices\n        current_indices = np.setdiff1d(current_indices, global_indices_to_remove)\n\n    return X[current_indices], y[current_indices]\n</code></pre>"},{"location":"api/techniques/#deviocsvm","title":"DeviOCSVM","text":""},{"location":"api/techniques/#fairsample.techniques.DeviOCSVM","title":"<code>fairsample.techniques.DeviOCSVM</code>","text":"<p>               Bases: <code>RandomUnderSampler</code></p> <p>Devi et al. One-Class SVM method (placeholder implementation).</p> <p>Currently uses random undersampling as a placeholder. TODO: Implement the actual Devi OCSVM algorithm.</p> Source code in <code>fairsample/techniques/devi_ocsvm.py</code> <pre><code>class DeviOCSVM(RandomUnderSampler):\n    \"\"\"\n    Devi et al. One-Class SVM method (placeholder implementation).\n\n    Currently uses random undersampling as a placeholder.\n    TODO: Implement the actual Devi OCSVM algorithm.\n    \"\"\"\n\n    def __init__(self, random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self._sampling_type = 'undersampling'\n</code></pre>"},{"location":"api/techniques/#fcmboostobu","title":"FCMBoostOBU","text":""},{"location":"api/techniques/#fairsample.techniques.FCMBoostOBU","title":"<code>fairsample.techniques.FCMBoostOBU</code>","text":"<p>               Bases: <code>RandomUnderSampler</code></p> <p>Fuzzy C-Means Boosted Overlap-Based Undersampling (placeholder implementation).</p> <p>Currently uses random undersampling as a placeholder. TODO: Implement the actual FCM Boost OBU algorithm.</p> Source code in <code>fairsample/techniques/fcm_boost_obu.py</code> <pre><code>class FCMBoostOBU(RandomUnderSampler):\n    \"\"\"\n    Fuzzy C-Means Boosted Overlap-Based Undersampling (placeholder implementation).\n\n    Currently uses random undersampling as a placeholder.\n    TODO: Implement the actual FCM Boost OBU algorithm.\n    \"\"\"\n\n    def __init__(self, random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self._sampling_type = 'hybrid'\n</code></pre>"},{"location":"api/techniques/#hybrid-methods","title":"Hybrid Methods","text":""},{"location":"api/techniques/#svddwsmote","title":"SVDDWSMOTE","text":""},{"location":"api/techniques/#fairsample.techniques.SVDDWSMOTE","title":"<code>fairsample.techniques.SVDDWSMOTE</code>","text":"<p>               Bases: <code>RandomOverSampler</code></p> <p>SVDD-based overlap handler (placeholder implementation).</p> <p>Currently uses random oversampling as a placeholder. TODO: Implement the actual SVDD WSMOTE algorithm.</p> Source code in <code>fairsample/techniques/svddwsmote.py</code> <pre><code>class SVDDWSMOTE(RandomOverSampler):\n    \"\"\"\n    SVDD-based overlap handler (placeholder implementation).\n\n    Currently uses random oversampling as a placeholder.\n    TODO: Implement the actual SVDD WSMOTE algorithm.\n    \"\"\"\n\n    def __init__(self, random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self._sampling_type = 'hybrid'\n</code></pre>"},{"location":"api/techniques/#odbot","title":"ODBOT","text":""},{"location":"api/techniques/#fairsample.techniques.ODBOT","title":"<code>fairsample.techniques.ODBOT</code>","text":"<p>               Bases: <code>RandomOverSampler</code></p> <p>Outlier Detection-Based Oversampling Technique (placeholder implementation).</p> <p>Currently uses random oversampling as a placeholder. TODO: Implement the actual ODBOT algorithm.</p> Source code in <code>fairsample/techniques/odbot.py</code> <pre><code>class ODBOT(RandomOverSampler):\n    \"\"\"\n    Outlier Detection-Based Oversampling Technique (placeholder implementation).\n\n    Currently uses random oversampling as a placeholder.\n    TODO: Implement the actual ODBOT algorithm.\n    \"\"\"\n\n    def __init__(self, random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self._sampling_type = 'oversampling'\n</code></pre>"},{"location":"api/techniques/#ehso","title":"EHSO","text":""},{"location":"api/techniques/#fairsample.techniques.EHSO","title":"<code>fairsample.techniques.EHSO</code>","text":"<p>               Bases: <code>RandomUnderSampler</code></p> <p>Evolutionary Hybrid Sampling in Overlapping scenarios (placeholder implementation).</p> <p>Currently uses random undersampling as a placeholder. TODO: Implement the actual EHSO algorithm.</p> Source code in <code>fairsample/techniques/ehso.py</code> <pre><code>class EHSO(RandomUnderSampler):\n    \"\"\"\n    Evolutionary Hybrid Sampling in Overlapping scenarios (placeholder implementation).\n\n    Currently uses random undersampling as a placeholder.\n    TODO: Implement the actual EHSO algorithm.\n    \"\"\"\n\n    def __init__(self, random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self._sampling_type = 'hybrid'\n</code></pre>"},{"location":"api/techniques/#clustering-based","title":"Clustering-Based","text":""},{"location":"api/techniques/#nbus","title":"NBUS","text":""},{"location":"api/techniques/#fairsample.techniques.NBUS","title":"<code>fairsample.techniques.NBUS</code>","text":"<p>               Bases: <code>NUS</code></p> <p>Neighbourhood-Based Undersampling (placeholder implementation).</p> <p>Currently uses NUS as a placeholder. TODO: Implement the actual NBUS variants.</p> Source code in <code>fairsample/techniques/nbus.py</code> <pre><code>class NBUS(NUS):\n    \"\"\"\n    Neighbourhood-Based Undersampling (placeholder implementation).\n\n    Currently uses NUS as a placeholder.\n    TODO: Implement the actual NBUS variants.\n    \"\"\"\n\n    def __init__(self, variant='basic', random_state=None):\n        super().__init__(n_neighbors=3, random_state=random_state)\n        self.variant = variant\n        self._sampling_type = 'undersampling'\n</code></pre>"},{"location":"api/techniques/#kmeansundersampling","title":"KMeansUndersampling","text":""},{"location":"api/techniques/#fairsample.techniques.KMeansUndersampling","title":"<code>fairsample.techniques.KMeansUndersampling</code>","text":"<p>               Bases: <code>RandomUnderSampler</code></p> <p>K-Means based undersampling (placeholder implementation).</p> <p>Currently uses random undersampling as a placeholder. TODO: Implement the actual K-Means undersampling variants.</p> Source code in <code>fairsample/techniques/kmeans_undersampling.py</code> <pre><code>class KMeansUndersampling(RandomUnderSampler):\n    \"\"\"\n    K-Means based undersampling (placeholder implementation).\n\n    Currently uses random undersampling as a placeholder.\n    TODO: Implement the actual K-Means undersampling variants.\n    \"\"\"\n\n    def __init__(self, variant='basic', random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self.variant = variant\n        self._sampling_type = 'undersampling'\n</code></pre>"},{"location":"api/techniques/#comprehensive","title":"Comprehensive","text":""},{"location":"api/techniques/#osm","title":"OSM","text":""},{"location":"api/techniques/#fairsample.techniques.OSM","title":"<code>fairsample.techniques.OSM</code>","text":"<p>               Bases: <code>RandomUnderSampler</code></p> <p>Overlap-Separating Model (placeholder implementation).</p> <p>Currently uses random undersampling as a placeholder. TODO: Implement the actual OSM algorithm.</p> Source code in <code>fairsample/techniques/osm.py</code> <pre><code>class OSM(RandomUnderSampler):\n    \"\"\"\n    Overlap-Separating Model (placeholder implementation).\n\n    Currently uses random undersampling as a placeholder.\n    TODO: Implement the actual OSM algorithm.\n    \"\"\"\n\n    def __init__(self, random_state=None):\n        super().__init__(sampling_strategy='auto', random_state=random_state)\n        self._sampling_type = 'hybrid'\n</code></pre>"},{"location":"api/techniques/#baselines","title":"Baselines","text":""},{"location":"api/techniques/#randomoversampler","title":"RandomOverSampler","text":"<p>From imbalanced-learn:</p> <pre><code>from imblearn.over_sampling import RandomOverSampler\n\nsampler = RandomOverSampler(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre>"},{"location":"api/techniques/#randomundersampler","title":"RandomUnderSampler","text":"<p>From imbalanced-learn:</p> <pre><code>from imblearn.under_sampling import RandomUnderSampler\n\nsampler = RandomUnderSampler(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre>"},{"location":"api/utils/","title":"Utils API Reference","text":"<p>Utility functions for comparing techniques and getting resampled data.</p>"},{"location":"api/utils/#compare_techniques","title":"compare_techniques","text":"<p>Compare multiple resampling techniques based on complexity measures.</p> <pre><code>from fairsample.utils import compare_techniques\n\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures='basic'\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>X</code>: array-like, shape (n_samples, n_features)<ul> <li>Feature matrix</li> </ul> </li> <li><code>y</code>: array-like, shape (n_samples,)<ul> <li>Target vector</li> </ul> </li> <li><code>techniques</code>: list of str<ul> <li>List of technique names to compare</li> </ul> </li> <li><code>complexity_measures</code>: str or list, default='basic'<ul> <li>Which measures to calculate:<ul> <li><code>'basic'</code>: Quick subset (N3, F1, N1, T1, imbalance_ratio)</li> <li><code>'all'</code>: All 40+ measures</li> <li><code>'feature'</code>: Feature overlap measures</li> <li><code>'instance'</code>: Instance overlap measures</li> <li><code>'structural'</code>: Structural measures</li> <li><code>'multiresolution'</code>: Multiresolution measures</li> <li>List of specific measures: <code>['N3', 'F1', 'N1']</code></li> </ul> </li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>results</code>: pandas.DataFrame<ul> <li>DataFrame with columns: technique, complexity measures, sample_size</li> </ul> </li> </ul> <p>Example:</p> <pre><code>results = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures=['N3', 'F1', 'N1']\n)\n\n# Sort by N3 (lower is better)\nprint(results.sort_values('N3'))\n</code></pre>"},{"location":"api/utils/#get_resampled_data","title":"get_resampled_data","text":"<p>Get resampled data for multiple techniques.</p> <pre><code>from fairsample.utils import get_resampled_data\n\ndata = get_resampled_data(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS']\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>X</code>: array-like, shape (n_samples, n_features)<ul> <li>Feature matrix</li> </ul> </li> <li><code>y</code>: array-like, shape (n_samples,)<ul> <li>Target vector</li> </ul> </li> <li><code>techniques</code>: list of str<ul> <li>List of technique names</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>data</code>: dict<ul> <li>Dictionary mapping technique names to dicts with keys:<ul> <li><code>'X'</code>: Resampled features</li> <li><code>'y'</code>: Resampled targets</li> </ul> </li> </ul> </li> </ul> <p>Example:</p> <pre><code>data = get_resampled_data(X, y, ['RFCL', 'NUS'])\n\n# Access resampled data\nX_rfcl = data['RFCL']['X']\ny_rfcl = data['RFCL']['y']\n\n# Save to CSV\nimport pandas as pd\nfor technique, info in data.items():\n    df = pd.DataFrame(info['X'])\n    df['target'] = info['y']\n    df.to_csv(f'{technique}_data.csv', index=False)\n</code></pre>"},{"location":"api/utils/#available-technique-names","title":"Available Technique Names","text":"<p>Use these strings in <code>techniques</code> parameter:</p> <p>Overlap-Based: - <code>'RFCL'</code> - <code>'NUS'</code> - <code>'URNS'</code> - <code>'DeviOCSVM'</code> - <code>'FCMBoostOBU'</code></p> <p>Hybrid: - <code>'SVDDWSMOTE'</code> - <code>'ODBOT'</code> - <code>'EHSO'</code></p> <p>Clustering-Based: - <code>'NBUS_centroid'</code> - <code>'NBUS_median'</code> - <code>'NBUS_nearest'</code> - <code>'NBUS_farthest'</code> - <code>'KMeansUndersampling_centroid'</code> - <code>'KMeansUndersampling_median'</code> - <code>'KMeansUndersampling_nearest'</code> - <code>'KMeansUndersampling_farthest'</code></p> <p>Comprehensive: - <code>'OSM'</code></p> <p>Baselines: - <code>'RandomOverSampler'</code> - <code>'RandomUnderSampler'</code></p>"},{"location":"complexity/feature-overlap/","title":"Feature Overlap Measures","text":"<p>Feature-level measures analyze how well individual features separate classes.</p>"},{"location":"complexity/feature-overlap/#f1-maximum-fishers-discriminant-ratio","title":"F1 - Maximum Fisher's Discriminant Ratio","text":"<p>Measures the maximum discriminative power across all features.</p> <pre><code>cm = ComplexityMeasures(X, y)\nf1 = cm.calculate_F1()\nprint(f\"F1: {f1:.4f}\")\n</code></pre> <p>Interpretation: - Higher values indicate better feature separability - Low F1 suggests poor feature discrimination</p>"},{"location":"complexity/feature-overlap/#f1v-directional-vector-maximum-fishers-discriminant-ratio","title":"F1v - Directional-Vector Maximum Fisher's Discriminant Ratio","text":"<p>Extends F1 by considering feature combinations.</p> <pre><code>f1v = cm.calculate_F1v()\n</code></pre> <p>Interpretation: - Higher values indicate better separability in feature space</p>"},{"location":"complexity/feature-overlap/#f2-volume-of-overlapping-region","title":"F2 - Volume of Overlapping Region","text":"<p>Measures the volume of the region where classes overlap.</p> <pre><code>f2 = cm.calculate_F2()\n</code></pre> <p>Interpretation: - Lower values indicate less overlap - 0.0: No overlap - 1.0: Complete overlap</p>"},{"location":"complexity/feature-overlap/#f3-maximum-individual-feature-efficiency","title":"F3 - Maximum Individual Feature Efficiency","text":"<p>Measures the efficiency of the best single feature.</p> <pre><code>f3 = cm.calculate_F3()\n</code></pre> <p>Interpretation: - Higher values indicate at least one feature separates classes well</p>"},{"location":"complexity/feature-overlap/#f4-collective-feature-efficiency","title":"F4 - Collective Feature Efficiency","text":"<p>Measures how well features collectively separate classes.</p> <pre><code>f4 = cm.calculate_F4()\n</code></pre> <p>Interpretation: - Higher values indicate good collective discrimination</p>"},{"location":"complexity/feature-overlap/#input-noise","title":"Input Noise","text":"<p>Estimates the amount of noise in input features.</p> <pre><code>noise = cm.calculate_input_noise()\n</code></pre> <p>Interpretation: - Lower values indicate cleaner data - Higher values suggest noisy features</p>"},{"location":"complexity/feature-overlap/#example-analyze-all-feature-measures","title":"Example: Analyze All Feature Measures","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\ncm = ComplexityMeasures(X, y)\nfeature_measures = cm.get_all_complexity_measures(measures='feature')\n\nfor measure, value in feature_measures.items():\n    print(f\"{measure}: {value:.4f}\")\n</code></pre>"},{"location":"complexity/feature-overlap/#next-steps","title":"Next Steps","text":"<ul> <li>Instance Overlap Measures</li> <li>Structural Measures</li> </ul>"},{"location":"complexity/instance-overlap/","title":"Instance Overlap Measures","text":"<p>Instance-level measures quantify overlap between classes at the data point level.</p>"},{"location":"complexity/instance-overlap/#n3-error-rate-of-nearest-neighbor","title":"N3 - Error Rate of Nearest Neighbor","text":"<p>Measures how often nearest neighbors have different class labels.</p> <pre><code>cm = ComplexityMeasures(X, y)\nn3 = cm.calculate_N3()\nprint(f\"N3: {n3:.4f}\")\n</code></pre> <p>Interpretation: - 0.0: No overlap, perfect separation - 0.1-0.3: Moderate overlap - &gt; 0.3: High overlap</p> <p>Best for: Quick assessment of overall overlap</p>"},{"location":"complexity/instance-overlap/#n4-non-linearity-of-nearest-neighbor","title":"N4 - Non-linearity of Nearest Neighbor","text":"<p>Measures non-linearity by interpolating between nearest neighbors.</p> <pre><code>n4 = cm.calculate_N4()\n</code></pre> <p>Interpretation: - Low: Linear boundary - High: Non-linear, complex boundary</p>"},{"location":"complexity/instance-overlap/#kdn-k-disagreeing-neighbors","title":"kDN - k-Disagreeing Neighbors","text":"<p>Fraction of instances with disagreeing neighbors.</p> <pre><code>kdn = cm.calculate_kDN(k=5)\n</code></pre> <p>Parameters: - <code>k</code>: Number of neighbors (default: 5)</p> <p>Interpretation: - Low: Clear class regions - High: Mixed neighborhoods</p>"},{"location":"complexity/instance-overlap/#cm-class-imbalance-metric","title":"CM - Class Imbalance Metric","text":"<p>Measures class imbalance combined with overlap.</p> <pre><code>cm_score = cm.calculate_CM()\n</code></pre> <p>Interpretation: - Higher values indicate more severe imbalance with overlap</p>"},{"location":"complexity/instance-overlap/#r-value-overlap-region-size","title":"R-value - Overlap Region Size","text":"<p>Estimates the size of the overlap region.</p> <pre><code>r_value = cm.calculate_R_value()\n</code></pre> <p>Interpretation: - 0.0: No overlap - 1.0: Complete overlap</p>"},{"location":"complexity/instance-overlap/#d3-disjunct-class-percentage","title":"D3 - Disjunct Class Percentage","text":"<p>Percentage of instances in disjunct regions.</p> <pre><code>d3 = cm.calculate_D3()\n</code></pre> <p>Interpretation: - High: Many isolated instances - Low: Cohesive class regions</p>"},{"location":"complexity/instance-overlap/#si-silhouette-index","title":"SI - Silhouette Index","text":"<p>Measures how well instances fit their class cluster.</p> <pre><code>si = cm.calculate_SI()\n</code></pre> <p>Interpretation: - 1.0: Perfect clustering - 0.0: Overlapping clusters - -1.0: Misclassified instances</p>"},{"location":"complexity/instance-overlap/#borderline-borderline-instance-ratio","title":"Borderline - Borderline Instance Ratio","text":"<p>Fraction of instances near the class boundary.</p> <pre><code>borderline = cm.calculate_borderline()\n</code></pre> <p>Interpretation: - High: Many boundary instances (difficult) - Low: Clear separation</p>"},{"location":"complexity/instance-overlap/#degree-of-overlap","title":"Degree of Overlap","text":"<p>Overall degree of class overlap.</p> <pre><code>overlap = cm.calculate_degree_of_overlap()\n</code></pre> <p>Interpretation: - 0.0: No overlap - 1.0: Complete overlap</p>"},{"location":"complexity/instance-overlap/#example-analyze-all-instance-measures","title":"Example: Analyze All Instance Measures","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\ncm = ComplexityMeasures(X, y)\n\n# Get all instance measures\ninstance_measures = cm.get_all_complexity_measures(measures='instance')\n\n# Print sorted by value\nfor measure, value in sorted(instance_measures.items(), key=lambda x: x[1]):\n    print(f\"{measure}: {value:.4f}\")\n</code></pre>"},{"location":"complexity/instance-overlap/#example-track-improvement","title":"Example: Track Improvement","text":"<pre><code>from fairsample import RFCL\n\n# Before resampling\ncm_before = ComplexityMeasures(X, y)\nn3_before = cm_before.calculate_N3()\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n\n# After resampling\ncm_after = ComplexityMeasures(X_resampled, y_resampled)\nn3_after = cm_after.calculate_N3()\n\n# Calculate improvement\nimprovement = (n3_before - n3_after) / n3_before * 100\nprint(f\"N3 improved by {improvement:.1f}%\")\n</code></pre>"},{"location":"complexity/instance-overlap/#next-steps","title":"Next Steps","text":"<ul> <li>Feature Overlap Measures</li> <li>Structural Measures</li> <li>Examples</li> </ul>"},{"location":"complexity/multiresolution/","title":"Multiresolution Measures","text":"<p>Multiresolution measures analyze complexity at multiple scales.</p>"},{"location":"complexity/multiresolution/#purity","title":"Purity","text":"<p>Measures class purity in local neighborhoods.</p> <pre><code>cm = ComplexityMeasures(X, y)\npurity = cm.calculate_purity()\n</code></pre> <p>Interpretation: - 1.0: Perfect purity (no mixing) - 0.0: Complete mixing</p>"},{"location":"complexity/multiresolution/#neighbourhood-separability","title":"Neighbourhood Separability","text":"<p>Measures how well neighborhoods separate classes.</p> <pre><code>ns = cm.calculate_neighbourhood_separability()\n</code></pre> <p>Interpretation: - Higher values indicate better separation</p>"},{"location":"complexity/multiresolution/#mrca-multiresolution-complexity-analysis","title":"MRCA - Multiresolution Complexity Analysis","text":"<p>Analyzes complexity across multiple resolutions.</p> <pre><code>mrca = cm.calculate_MRCA()\n</code></pre> <p>Interpretation: - Captures complexity at different scales</p>"},{"location":"complexity/multiresolution/#c1-entropy-of-class-proportions","title":"C1 - Entropy of Class Proportions","text":"<p>Measures entropy of class distribution.</p> <pre><code>c1 = cm.calculate_C1()\n</code></pre> <p>Interpretation: - Higher values indicate more balanced classes</p>"},{"location":"complexity/multiresolution/#c2-imbalance-ratio","title":"C2 - Imbalance Ratio","text":"<p>Measures the degree of class imbalance.</p> <pre><code>c2 = cm.calculate_C2()\n</code></pre> <p>Interpretation: - 1.0: Perfectly balanced - Higher values indicate more imbalance</p>"},{"location":"complexity/multiresolution/#example-analyze-all-multiresolution-measures","title":"Example: Analyze All Multiresolution Measures","text":"<pre><code>cm = ComplexityMeasures(X, y)\nmulti = cm.get_all_complexity_measures(measures='multiresolution')\n\nfor measure, value in multi.items():\n    print(f\"{measure}: {value:.4f}\")\n</code></pre>"},{"location":"complexity/multiresolution/#next-steps","title":"Next Steps","text":"<ul> <li>Feature Overlap</li> <li>Instance Overlap</li> <li>Examples</li> </ul>"},{"location":"complexity/overview/","title":"Complexity Measures Overview","text":"<p>Complexity measures quantify dataset difficulty and class overlap. Use them to understand why your dataset is challenging and which technique works best.</p>"},{"location":"complexity/overview/#why-complexity-measures","title":"Why Complexity Measures?","text":"<p>Traditional metrics (accuracy, F1-score) tell you how well a model performs, but not why it struggles. Complexity measures reveal:</p> <ul> <li>Class overlap - How much classes overlap in feature space</li> <li>Boundary complexity - How irregular the decision boundary is</li> <li>Feature discriminability - Which features separate classes well</li> <li>Structural issues - Clusters, outliers, and noise</li> </ul>"},{"location":"complexity/overview/#categories","title":"Categories","text":""},{"location":"complexity/overview/#feature-overlap-6-measures","title":"Feature Overlap (6 measures)","text":"<p>Analyze how well individual features separate classes.</p> <ul> <li>F1, F1v, F2, F3, F4, Input Noise</li> </ul> <p>Learn more \u2192</p>"},{"location":"complexity/overview/#instance-overlap-9-measures","title":"Instance Overlap (9 measures)","text":"<p>Measure overlap at the instance level.</p> <ul> <li>N3, N4, kDN, CM, R-value, D3, SI, Borderline, Degree of Overlap</li> </ul> <p>Learn more \u2192</p>"},{"location":"complexity/overview/#structural-9-measures","title":"Structural (9 measures)","text":"<p>Analyze dataset structure and topology.</p> <ul> <li>N1, N2, T1, DBC, LSC, Clust, NSG, ICSV, ONB</li> </ul> <p>Learn more \u2192</p>"},{"location":"complexity/overview/#multiresolution-5-measures","title":"Multiresolution (5 measures)","text":"<p>Examine complexity at multiple scales.</p> <ul> <li>Purity, Neighbourhood Separability, MRCA, C1, C2</li> </ul> <p>Learn more \u2192</p>"},{"location":"complexity/overview/#basic-usage","title":"Basic Usage","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\n# Create analyzer\ncm = ComplexityMeasures(X, y)\n\n# Get basic overlap measures\nbasic = cm.analyze_overlap()\nprint(f\"N3: {basic['N3']:.4f}\")\nprint(f\"F1: {basic['F1']:.4f}\")\n\n# Get all measures\nall_measures = cm.get_all_complexity_measures(measures='all')\nprint(all_measures)\n</code></pre>"},{"location":"complexity/overview/#get-specific-categories","title":"Get Specific Categories","text":"<pre><code># Feature overlap only\nfeature = cm.get_all_complexity_measures(measures='feature')\n\n# Instance overlap only\ninstance = cm.get_all_complexity_measures(measures='instance')\n\n# Structural only\nstructural = cm.get_all_complexity_measures(measures='structural')\n\n# Multiresolution only\nmulti = cm.get_all_complexity_measures(measures='multiresolution')\n</code></pre>"},{"location":"complexity/overview/#get-specific-measures","title":"Get Specific Measures","text":"<pre><code># Select specific measures\nselected = cm.get_all_complexity_measures(\n    measures=['N3', 'F1', 'N1', 'T1']\n)\n</code></pre>"},{"location":"complexity/overview/#compare-beforeafter-resampling","title":"Compare Before/After Resampling","text":"<pre><code>from fairsample import RFCL\nfrom fairsample.complexity import compare_pre_post_overlap\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n\n# Compare complexity\ncomparison = compare_pre_post_overlap(X, y, X_resampled, y_resampled)\n\nprint(\"Improvements:\")\nfor measure, improvement in comparison['improvements'].items():\n    print(f\"{measure}: {improvement:.2%}\")\n</code></pre>"},{"location":"complexity/overview/#interpreting-results","title":"Interpreting Results","text":""},{"location":"complexity/overview/#lower-is-better","title":"Lower is Better","text":"<p>Most measures: lower values indicate less complexity/overlap.</p> <ul> <li>N3 &lt; 0.1: Low overlap, easy dataset</li> <li>N3 0.1-0.3: Moderate overlap</li> <li>N3 &gt; 0.3: High overlap, difficult dataset</li> </ul>"},{"location":"complexity/overview/#higher-is-better","title":"Higher is Better","text":"<p>Some measures (like F1): higher values indicate better separability.</p>"},{"location":"complexity/overview/#common-patterns","title":"Common Patterns","text":"Pattern Likely Issue Recommended Action High N3, High F1 Instance overlap Use RFCL, NUS, URNS High N3, Low F1 Feature overlap Feature engineering High N1, Low N3 Boundary complexity Use SVDDWSMOTE, OSM High Clust Multiple clusters Use NBUS, KMeans"},{"location":"complexity/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Feature Overlap Measures</li> <li>Instance Overlap Measures</li> <li>Structural Measures</li> <li>Multiresolution Measures</li> </ul>"},{"location":"complexity/structural/","title":"Structural Measures","text":"<p>Structural measures analyze the topology and geometry of the dataset.</p>"},{"location":"complexity/structural/#n1-fraction-of-borderline-points","title":"N1 - Fraction of Borderline Points","text":"<p>Fraction of points on the class boundary using MST.</p> <pre><code>cm = ComplexityMeasures(X, y)\nn1 = cm.calculate_N1()\n</code></pre> <p>Interpretation: - Higher values indicate more boundary complexity</p>"},{"location":"complexity/structural/#n2-ratio-of-intraextra-class-nearest-neighbor-distance","title":"N2 - Ratio of Intra/Extra Class Nearest Neighbor Distance","text":"<p>Compares distances within and between classes.</p> <pre><code>n2 = cm.calculate_N2()\n</code></pre> <p>Interpretation: - Lower values indicate better separation</p>"},{"location":"complexity/structural/#t1-fraction-of-hyperspheres-covering-data","title":"T1 - Fraction of Hyperspheres Covering Data","text":"<p>Measures how many hyperspheres are needed to cover the data.</p> <pre><code>t1 = cm.calculate_T1()\n</code></pre> <p>Interpretation: - Higher values indicate more complex structure</p>"},{"location":"complexity/structural/#dbc-distance-based-complexity","title":"DBC - Distance-Based Complexity","text":"<p>Measures complexity based on distance distributions.</p> <pre><code>dbc = cm.calculate_DBC()\n</code></pre>"},{"location":"complexity/structural/#lsc-local-set-cardinality","title":"LSC - Local Set Cardinality","text":"<p>Measures the average size of local neighborhoods.</p> <pre><code>lsc = cm.calculate_LSC()\n</code></pre>"},{"location":"complexity/structural/#clust-clustering-measure","title":"Clust - Clustering Measure","text":"<p>Measures how well data forms clusters.</p> <pre><code>clust = cm.calculate_Clust()\n</code></pre> <p>Interpretation: - Higher values indicate more distinct clusters</p>"},{"location":"complexity/structural/#nsg-number-of-spanning-graphs","title":"NSG - Number of Spanning Graphs","text":"<p>Counts the number of connected components.</p> <pre><code>nsg = cm.calculate_NSG()\n</code></pre>"},{"location":"complexity/structural/#icsv-inter-class-to-intra-class-similarity-variance","title":"ICSV - Inter-Class to Intra-Class Similarity Variance","text":"<p>Compares inter-class and intra-class variance.</p> <pre><code>icsv = cm.calculate_ICSV()\n</code></pre>"},{"location":"complexity/structural/#onb-overlap-of-neighborhoods-between-classes","title":"ONB - Overlap of Neighborhoods Between Classes","text":"<p>Measures neighborhood overlap between classes.</p> <pre><code>onb = cm.calculate_ONB()\n</code></pre>"},{"location":"complexity/structural/#example-analyze-all-structural-measures","title":"Example: Analyze All Structural Measures","text":"<pre><code>cm = ComplexityMeasures(X, y)\nstructural = cm.get_all_complexity_measures(measures='structural')\n\nfor measure, value in structural.items():\n    print(f\"{measure}: {value:.4f}\")\n</code></pre>"},{"location":"complexity/structural/#next-steps","title":"Next Steps","text":"<ul> <li>Multiresolution Measures</li> <li>Examples</li> </ul>"},{"location":"examples/basic-usage/","title":"Basic Usage Examples","text":"<p>Simple examples to get you started with the toolkit.</p>"},{"location":"examples/basic-usage/#example-1-single-technique","title":"Example 1: Single Technique","text":"<pre><code>from fairsample import RFCL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport pandas as pd\n\n# Load data\ndf = pd.read_csv('data.csv')\nX = df.drop('target', axis=1)\ny = df['target']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\n# Apply RFCL\nsampler = RFCL(random_state=42)\nX_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n\n# Train model\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train_resampled, y_train_resampled)\n\n# Evaluate\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n</code></pre>"},{"location":"examples/basic-usage/#example-2-check-complexity-first","title":"Example 2: Check Complexity First","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\n# Analyze complexity\ncm = ComplexityMeasures(X_train, y_train)\ncomplexity = cm.analyze_overlap()\n\nprint(f\"N3 (overlap): {complexity['N3']:.4f}\")\nprint(f\"F1 (feature overlap): {complexity['F1']:.4f}\")\nprint(f\"Imbalance ratio: {complexity['imbalance_ratio']:.2f}\")\n\n# Decide based on complexity\nif complexity['N3'] &gt; 0.3:\n    print(\"High overlap detected - using RFCL\")\n    sampler = RFCL(random_state=42)\nelse:\n    print(\"Low overlap - using random undersampling\")\n    from imblearn.under_sampling import RandomUnderSampler\n    sampler = RandomUnderSampler(random_state=42)\n\nX_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n</code></pre>"},{"location":"examples/basic-usage/#example-3-save-resampled-data","title":"Example 3: Save Resampled Data","text":"<pre><code>from fairsample import RFCL\nimport pandas as pd\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n\n# Convert to DataFrame\ndf_resampled = pd.DataFrame(X_resampled, columns=X.columns)\ndf_resampled['target'] = y_resampled\n\n# Save to CSV\ndf_resampled.to_csv('resampled_data.csv', index=False)\nprint(f\"Saved {len(df_resampled)} samples\")\n</code></pre>"},{"location":"examples/basic-usage/#example-4-multiple-datasets","title":"Example 4: Multiple Datasets","text":"<pre><code>from fairsample.utils import get_resampled_data\n\n# Get resampled data for multiple techniques\ndata = get_resampled_data(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS']\n)\n\n# Save each to CSV\nfor technique, info in data.items():\n    df = pd.DataFrame(info['X'])\n    df['target'] = info['y']\n    df.to_csv(f'{technique}_data.csv', index=False)\n    print(f\"{technique}: {len(df)} samples\")\n</code></pre>"},{"location":"examples/basic-usage/#example-5-track-improvement","title":"Example 5: Track Improvement","text":"<pre><code>from fairsample import RFCL\nfrom fairsample.complexity import compare_pre_post_overlap\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n\n# Compare complexity\ncomparison = compare_pre_post_overlap(X, y, X_resampled, y_resampled)\n\nprint(\"Before resampling:\")\nprint(comparison['before'])\n\nprint(\"\\nAfter resampling:\")\nprint(comparison['after'])\n\nprint(\"\\nImprovements:\")\nfor measure, improvement in comparison['improvements'].items():\n    print(f\"{measure}: {improvement:+.2%}\")\n</code></pre>"},{"location":"examples/basic-usage/#example-6-cross-validation","title":"Example 6: Cross-Validation","text":"<pre><code>from fairsample import RFCL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom imblearn.pipeline import Pipeline\n\n# Create pipeline\npipeline = Pipeline([\n    ('sampler', RFCL(random_state=42)),\n    ('classifier', RandomForestClassifier(random_state=42))\n])\n\n# Cross-validation\nscores = cross_val_score(pipeline, X, y, cv=5, scoring='f1_macro')\nprint(f\"F1-Score: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n</code></pre>"},{"location":"examples/basic-usage/#example-7-get-all-complexity-measures","title":"Example 7: Get All Complexity Measures","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\ncm = ComplexityMeasures(X, y)\n\n# Get all measures\nall_measures = cm.get_all_complexity_measures(measures='all')\n\n# Print sorted by value\nprint(\"Complexity Measures (sorted):\")\nfor measure, value in sorted(all_measures.items(), key=lambda x: x[1]):\n    print(f\"{measure:30s}: {value:.4f}\")\n</code></pre>"},{"location":"examples/basic-usage/#example-8-category-specific-measures","title":"Example 8: Category-Specific Measures","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\ncm = ComplexityMeasures(X, y)\n\n# Get feature overlap measures\nfeature = cm.get_all_complexity_measures(measures='feature')\nprint(\"Feature Overlap:\", feature)\n\n# Get instance overlap measures\ninstance = cm.get_all_complexity_measures(measures='instance')\nprint(\"Instance Overlap:\", instance)\n\n# Get structural measures\nstructural = cm.get_all_complexity_measures(measures='structural')\nprint(\"Structural:\", structural)\n</code></pre>"},{"location":"examples/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Comparing Techniques</li> <li>Complete Workflows</li> <li>API Reference</li> </ul>"},{"location":"examples/comparison/","title":"Comparing Techniques","text":"<p>Learn how to compare multiple resampling techniques to find the best one for your data.</p>"},{"location":"examples/comparison/#quick-comparison","title":"Quick Comparison","text":"<pre><code>from fairsample.utils import compare_techniques\n\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS', 'SVDDWSMOTE'],\n    complexity_measures='basic'\n)\n\n# View results\nprint(results)\n\n# Sort by N3 (lower is better)\nprint(results.sort_values('N3'))\n</code></pre>"},{"location":"examples/comparison/#compare-with-all-measures","title":"Compare with All Measures","text":"<pre><code>results = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures='all'\n)\n\n# View specific columns\nprint(results[['technique', 'N3', 'F1', 'N1', 'sample_size']])\n</code></pre>"},{"location":"examples/comparison/#compare-specific-measures","title":"Compare Specific Measures","text":"<pre><code>results = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures=['N3', 'F1', 'N1', 'T1']\n)\n\nprint(results)\n</code></pre>"},{"location":"examples/comparison/#visualize-comparison","title":"Visualize Comparison","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS', 'SVDDWSMOTE', 'NBUS_centroid'],\n    complexity_measures='basic'\n)\n\n# Plot N3 comparison\nplt.figure(figsize=(10, 6))\nsns.barplot(data=results, x='technique', y='N3')\nplt.xticks(rotation=45)\nplt.title('N3 Overlap Comparison')\nplt.ylabel('N3 (lower is better)')\nplt.tight_layout()\nplt.savefig('n3_comparison.png')\nplt.show()\n</code></pre>"},{"location":"examples/comparison/#compare-multiple-measures","title":"Compare Multiple Measures","text":"<pre><code>import matplotlib.pyplot as plt\n\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures=['N3', 'F1', 'N1']\n)\n\n# Plot multiple measures\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nfor i, measure in enumerate(['N3', 'F1', 'N1']):\n    axes[i].bar(results['technique'], results[measure])\n    axes[i].set_title(f'{measure} Comparison')\n    axes[i].set_xlabel('Technique')\n    axes[i].set_ylabel(measure)\n    axes[i].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.savefig('multi_measure_comparison.png')\nplt.show()\n</code></pre>"},{"location":"examples/comparison/#compare-with-original-data","title":"Compare with Original Data","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\n# Original complexity\ncm_original = ComplexityMeasures(X, y)\noriginal_n3 = cm_original.calculate_N3()\n\n# Compare techniques\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures='basic'\n)\n\n# Add original as baseline\nresults.loc[len(results)] = {\n    'technique': 'Original',\n    'N3': original_n3,\n    'sample_size': len(X)\n}\n\nprint(results.sort_values('N3'))\n</code></pre>"},{"location":"examples/comparison/#statistical-comparison","title":"Statistical Comparison","text":"<pre><code>from fairsample.utils import compare_techniques\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.pipeline import Pipeline\nimport numpy as np\n\ntechniques = ['RFCL', 'NUS', 'URNS']\nresults = []\n\nfor technique in techniques:\n    # Create pipeline\n    pipeline = Pipeline([\n        ('sampler', eval(technique)(random_state=42)),\n        ('classifier', RandomForestClassifier(random_state=42))\n    ])\n\n    # Cross-validation\n    scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1_macro')\n\n    results.append({\n        'technique': technique,\n        'mean_f1': scores.mean(),\n        'std_f1': scores.std()\n    })\n\n# Print results\nimport pandas as pd\ndf_results = pd.DataFrame(results)\nprint(df_results.sort_values('mean_f1', ascending=False))\n</code></pre>"},{"location":"examples/comparison/#compare-execution-time","title":"Compare Execution Time","text":"<pre><code>import time\nfrom fairsample.utils import get_resampled_data\n\ntechniques = ['RFCL', 'NUS', 'URNS', 'NBUS_centroid']\ntiming_results = []\n\nfor technique in techniques:\n    start = time.time()\n    data = get_resampled_data(X, y, [technique])\n    elapsed = time.time() - start\n\n    timing_results.append({\n        'technique': technique,\n        'time_seconds': elapsed,\n        'samples': len(data[technique]['X'])\n    })\n\n# Print results\nimport pandas as pd\ndf_timing = pd.DataFrame(timing_results)\nprint(df_timing.sort_values('time_seconds'))\n</code></pre>"},{"location":"examples/comparison/#find-best-technique","title":"Find Best Technique","text":"<pre><code>from fairsample.utils import compare_techniques\n\ndef find_best_technique(X, y, techniques, metric='N3'):\n    \"\"\"Find the best technique based on a complexity metric.\"\"\"\n    results = compare_techniques(\n        X, y,\n        techniques=techniques,\n        complexity_measures='basic'\n    )\n\n    # Lower is better for most metrics\n    best = results.sort_values(metric).iloc[0]\n\n    return best['technique'], best[metric]\n\n# Find best\ntechniques = ['RFCL', 'NUS', 'URNS', 'SVDDWSMOTE', 'NBUS_centroid']\nbest_technique, best_score = find_best_technique(X, y, techniques)\n\nprint(f\"Best technique: {best_technique}\")\nprint(f\"N3 score: {best_score:.4f}\")\n</code></pre>"},{"location":"examples/comparison/#next-steps","title":"Next Steps","text":"<ul> <li>Complete Workflows</li> <li>Basic Usage</li> <li>API Reference</li> </ul>"},{"location":"examples/workflows/","title":"Complete Workflows","text":"<p>End-to-end workflows for common use cases.</p>"},{"location":"examples/workflows/#workflow-1-quick-single-technique","title":"Workflow 1: Quick Single Technique","text":"<pre><code>from fairsample import RFCL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# Load and split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Resample\nsampler = RFCL(random_state=42)\nX_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n\n# Train and evaluate\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train_res, y_train_res)\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n</code></pre>"},{"location":"examples/workflows/#workflow-2-complexity-guided-selection","title":"Workflow 2: Complexity-Guided Selection","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\nfrom fairsample import RFCL, NUS\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Analyze complexity\ncm = ComplexityMeasures(X_train, y_train)\ncomplexity = cm.analyze_overlap()\n\n# Choose technique based on complexity\nif complexity['N3'] &gt; 0.3:\n    print(\"High overlap - using RFCL\")\n    sampler = RFCL(random_state=42)\nelif complexity['N3'] &gt; 0.1:\n    print(\"Moderate overlap - using NUS\")\n    sampler = NUS(random_state=42)\nelse:\n    print(\"Low overlap - using random undersampling\")\n    sampler = RandomUnderSampler(random_state=42)\n\n# Apply and train\nX_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train_res, y_train_res)\n</code></pre>"},{"location":"examples/workflows/#workflow-3-compare-and-select-best","title":"Workflow 3: Compare and Select Best","text":"<pre><code>from fairsample.utils import compare_techniques\nfrom fairsample import RFCL\n\n# Compare techniques\nresults = compare_techniques(\n    X_train, y_train,\n    techniques=['RFCL', 'NUS', 'URNS', 'NBUS_centroid'],\n    complexity_measures='basic'\n)\n\n# Select best (lowest N3)\nbest_technique = results.sort_values('N3').iloc[0]['technique']\nprint(f\"Best technique: {best_technique}\")\n\n# Apply best technique\nsampler = eval(best_technique)(random_state=42)\nX_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n\n# Train\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train_res, y_train_res)\n</code></pre>"},{"location":"examples/workflows/#workflow-4-track-improvement","title":"Workflow 4: Track Improvement","text":"<pre><code>from fairsample import RFCL\nfrom fairsample.complexity import compare_pre_post_overlap\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\n\n# Before resampling\nclf_before = RandomForestClassifier(random_state=42)\nclf_before.fit(X_train, y_train)\nf1_before = f1_score(y_test, clf_before.predict(X_test), average='macro')\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n\n# After resampling\nclf_after = RandomForestClassifier(random_state=42)\nclf_after.fit(X_train_res, y_train_res)\nf1_after = f1_score(y_test, clf_after.predict(X_test), average='macro')\n\n# Compare complexity\ncomparison = compare_pre_post_overlap(X_train, y_train, X_train_res, y_train_res)\n\nprint(f\"F1 Before: {f1_before:.4f}\")\nprint(f\"F1 After: {f1_after:.4f}\")\nprint(f\"F1 Improvement: {(f1_after - f1_before):.4f}\")\nprint(f\"\\nComplexity Improvements:\")\nfor measure, improvement in comparison['improvements'].items():\n    print(f\"{measure}: {improvement:+.2%}\")\n</code></pre>"},{"location":"examples/workflows/#workflow-5-export-multiple-datasets","title":"Workflow 5: Export Multiple Datasets","text":"<pre><code>from fairsample.utils import get_resampled_data\nimport pandas as pd\n\n# Get resampled data for multiple techniques\ndata = get_resampled_data(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS', 'NBUS_centroid']\n)\n\n# Save each to CSV\nfor technique, info in data.items():\n    df = pd.DataFrame(info['X'], columns=X.columns)\n    df['target'] = info['y']\n    df.to_csv(f'data_{technique}.csv', index=False)\n    print(f\"Saved {technique}: {len(df)} samples\")\n</code></pre>"},{"location":"examples/workflows/#workflow-6-cross-validation-pipeline","title":"Workflow 6: Cross-Validation Pipeline","text":"<pre><code>from fairsample import RFCL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom imblearn.pipeline import Pipeline\n\n# Create pipeline\npipeline = Pipeline([\n    ('sampler', RFCL(random_state=42)),\n    ('classifier', RandomForestClassifier(random_state=42))\n])\n\n# Cross-validation\nscores = cross_val_score(pipeline, X, y, cv=5, scoring='f1_macro')\nprint(f\"F1-Score: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n</code></pre>"},{"location":"examples/workflows/#workflow-7-hyperparameter-tuning","title":"Workflow 7: Hyperparameter Tuning","text":"<pre><code>from fairsample import RFCL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.pipeline import Pipeline\n\n# Create pipeline\npipeline = Pipeline([\n    ('sampler', RFCL(random_state=42)),\n    ('classifier', RandomForestClassifier(random_state=42))\n])\n\n# Parameter grid\nparam_grid = {\n    'sampler__n_estimators': [50, 100, 200],\n    'classifier__n_estimators': [50, 100, 200],\n    'classifier__max_depth': [None, 10, 20]\n}\n\n# Grid search\ngrid = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\ngrid.fit(X_train, y_train)\n\nprint(f\"Best params: {grid.best_params_}\")\nprint(f\"Best score: {grid.best_score_:.4f}\")\n</code></pre>"},{"location":"examples/workflows/#workflow-8-production-pipeline","title":"Workflow 8: Production Pipeline","text":"<pre><code>from fairsample import RFCL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.pipeline import Pipeline\nimport joblib\n\n# Create full pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('sampler', RFCL(random_state=42)),\n    ('classifier', RandomForestClassifier(random_state=42))\n])\n\n# Train\npipeline.fit(X_train, y_train)\n\n# Save\njoblib.dump(pipeline, 'model_pipeline.pkl')\n\n# Load and predict\nloaded_pipeline = joblib.load('model_pipeline.pkl')\npredictions = loaded_pipeline.predict(X_new)\n</code></pre>"},{"location":"examples/workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage</li> <li>Comparing Techniques</li> <li>API Reference</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.8 or higher</li> <li>pip package manager</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install fairsample\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<pre><code>git clone https://github.com/yourusername/fairsample.git\ncd fairsample\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>The package will automatically install:</p> <ul> <li>numpy &gt;= 1.20.0</li> <li>scikit-learn &gt;= 1.0.0</li> <li>scipy &gt;= 1.7.0</li> <li>pandas &gt;= 1.3.0</li> <li>matplotlib &gt;= 3.4.0</li> <li>seaborn &gt;= 0.11.0</li> <li>imbalanced-learn &gt;= 0.9.0</li> </ul>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For additional features:</p> <pre><code># Fuzzy logic support\npip install scikit-fuzzy&gt;=0.4.2\n\n# Optimization methods\npip install cvxopt&gt;=1.2.0\n\n# Development tools\npip install fairsample[dev]\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import fairsample\nprint(fairsample.__version__)\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#import-errors","title":"Import Errors","text":"<p>If you get import errors, ensure all dependencies are installed:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#windows-users","title":"Windows Users","text":"<p>Some packages may require Visual C++ build tools. Download from Microsoft.</p>"},{"location":"getting-started/installation/#mac-users-with-m1m2","title":"Mac Users with M1/M2","text":"<p>Use conda for better compatibility:</p> <pre><code>conda install numpy scipy scikit-learn\npip install fairsample\n</code></pre>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get up and running with FairSample in minutes.</p>"},{"location":"getting-started/quick-start/#basic-resampling","title":"Basic Resampling","text":"<pre><code>from fairsample import RFCL\nimport pandas as pd\n\n# Load your data\ndf = pd.read_csv('data.csv')\nX = df.drop('target', axis=1)\ny = df['target']\n\n# Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n\n# Train your model\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf.fit(X_resampled, y_resampled)\n</code></pre>"},{"location":"getting-started/quick-start/#check-complexity","title":"Check Complexity","text":"<pre><code>from fairsample.complexity import ComplexityMeasures\n\n# Analyze your data\ncm = ComplexityMeasures(X, y)\ncomplexity = cm.analyze_overlap()\n\nprint(f\"N3 (overlap): {complexity['N3']:.4f}\")\nprint(f\"Imbalance ratio: {complexity['imbalance_ratio']:.2f}\")\n</code></pre>"},{"location":"getting-started/quick-start/#compare-techniques","title":"Compare Techniques","text":"<pre><code>from fairsample.utils import compare_techniques\n\n# Compare multiple techniques\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS'],\n    complexity_measures='basic'\n)\n\n# View results\nprint(results.sort_values('N3'))\n</code></pre>"},{"location":"getting-started/quick-start/#complete-workflow","title":"Complete Workflow","text":"<pre><code>from fairsample import RFCL\nfrom fairsample.complexity import ComplexityMeasures, compare_pre_post_overlap\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 1. Check original complexity\ncm = ComplexityMeasures(X, y)\noriginal = cm.analyze_overlap()\nprint(f\"Original N3: {original['N3']:.4f}\")\n\n# 2. Apply resampling\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n\n# 3. Compare complexity\ncomparison = compare_pre_post_overlap(X, y, X_resampled, y_resampled)\nprint(f\"Improvement: {comparison['improvements']}\")\n\n# 4. Train and evaluate\nclf = RandomForestClassifier(random_state=42)\nscores = cross_val_score(clf, X_resampled, y_resampled, cv=5)\nprint(f\"Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about all techniques</li> <li>Explore complexity measures</li> <li>See more examples</li> </ul>"},{"location":"techniques/clustering/","title":"Clustering-Based Methods","text":"<p>Clustering-based methods use clustering to identify and handle overlapping regions.</p>"},{"location":"techniques/clustering/#nbus-neighbourhood-based-undersampling","title":"NBUS - Neighbourhood-Based Undersampling","text":"<p>Uses clustering with 4 different selection strategies.</p>"},{"location":"techniques/clustering/#variants","title":"Variants","text":"<pre><code>from fairsample import NBUS\n\n# Centroid: Select cluster centroids\nsampler = NBUS(variant='centroid', n_clusters=5, random_state=42)\n\n# Median: Select median points\nsampler = NBUS(variant='median', n_clusters=5, random_state=42)\n\n# Nearest: Select nearest to centroid\nsampler = NBUS(variant='nearest', n_clusters=5, random_state=42)\n\n# Farthest: Select farthest from centroid\nsampler = NBUS(variant='farthest', n_clusters=5, random_state=42)\n\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>variant</code>: Selection strategy ('centroid', 'median', 'nearest', 'farthest') - <code>n_clusters</code>: Number of clusters (default: 5) - <code>random_state</code>: Random seed</p> <p>Best for: Large datasets, fast execution needed</p>"},{"location":"techniques/clustering/#kmeansundersampling","title":"KMeansUndersampling","text":"<p>Uses K-Means clustering with 4 selection strategies.</p>"},{"location":"techniques/clustering/#variants_1","title":"Variants","text":"<pre><code>from fairsample import KMeansUndersampling\n\n# Centroid: Select cluster centroids\nsampler = KMeansUndersampling(variant='centroid', n_clusters=5, random_state=42)\n\n# Median: Select median points\nsampler = KMeansUndersampling(variant='median', n_clusters=5, random_state=42)\n\n# Nearest: Select nearest to centroid\nsampler = KMeansUndersampling(variant='nearest', n_clusters=5, random_state=42)\n\n# Farthest: Select farthest from centroid\nsampler = KMeansUndersampling(variant='farthest', n_clusters=5, random_state=42)\n\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>variant</code>: Selection strategy ('centroid', 'median', 'nearest', 'farthest') - <code>n_clusters</code>: Number of clusters (default: 5) - <code>random_state</code>: Random seed</p> <p>Best for: Large datasets, well-defined clusters</p>"},{"location":"techniques/clustering/#choosing-a-variant","title":"Choosing a Variant","text":"<ul> <li>Centroid: Balanced representation</li> <li>Median: Robust to outliers</li> <li>Nearest: Preserve cluster core</li> <li>Farthest: Preserve cluster boundary</li> </ul>"},{"location":"techniques/clustering/#comparison","title":"Comparison","text":"<pre><code>from fairsample.utils import compare_techniques\n\nresults = compare_techniques(\n    X, y,\n    techniques=[\n        'NBUS_centroid', 'NBUS_median',\n        'KMeansUndersampling_centroid', 'KMeansUndersampling_median'\n    ],\n    complexity_measures='basic'\n)\n\nprint(results[['technique', 'N3', 'sample_size']])\n</code></pre>"},{"location":"techniques/clustering/#example-find-best-variant","title":"Example: Find Best Variant","text":"<pre><code>from fairsample import NBUS\nfrom fairsample.complexity import ComplexityMeasures\n\nvariants = ['centroid', 'median', 'nearest', 'farthest']\nresults = []\n\nfor variant in variants:\n    sampler = NBUS(variant=variant, random_state=42)\n    X_res, y_res = sampler.fit_resample(X, y)\n\n    cm = ComplexityMeasures(X_res, y_res)\n    n3 = cm.calculate_N3()\n\n    results.append({\n        'variant': variant,\n        'N3': n3,\n        'samples': len(X_res)\n    })\n\n# Print results\nimport pandas as pd\ndf = pd.DataFrame(results)\nprint(df.sort_values('N3'))\n</code></pre>"},{"location":"techniques/clustering/#next-steps","title":"Next Steps","text":"<ul> <li>Overlap-Based Methods</li> <li>Hybrid Methods</li> <li>API Reference</li> </ul>"},{"location":"techniques/hybrid/","title":"Hybrid Methods","text":"<p>Hybrid methods combine undersampling and oversampling strategies.</p>"},{"location":"techniques/hybrid/#svddwsmote","title":"SVDDWSMOTE","text":"<p>Combines Support Vector Data Description with SMOTE.</p> <pre><code>from fairsample import SVDDWSMOTE\n\nsampler = SVDDWSMOTE(\n    nu=0.5,\n    kernel='rbf',\n    gamma='scale',\n    k_neighbors=5,\n    random_state=42\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>nu</code>: SVDD parameter (default: 0.5) - <code>kernel</code>: Kernel type (default: 'rbf') - <code>gamma</code>: Kernel coefficient (default: 'scale') - <code>k_neighbors</code>: SMOTE neighbors (default: 5)</p> <p>Best for: Small datasets with non-linear boundaries</p>"},{"location":"techniques/hybrid/#odbot-outlier-detection-based-oversampling-technique","title":"ODBOT - Outlier Detection-Based Oversampling Technique","text":"<p>Uses outlier detection to guide oversampling.</p> <pre><code>from fairsample import ODBOT\n\nsampler = ODBOT(\n    contamination=0.1,\n    n_neighbors=5,\n    random_state=42\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>contamination</code>: Expected outlier proportion (default: 0.1) - <code>n_neighbors</code>: Number of neighbors (default: 5)</p> <p>Best for: Datasets with outliers</p>"},{"location":"techniques/hybrid/#ehso-evolutionary-hybrid-sampling","title":"EHSO - Evolutionary Hybrid Sampling","text":"<p>Uses evolutionary algorithms for hybrid sampling.</p> <pre><code>from fairsample import EHSO\n\nsampler = EHSO(\n    population_size=50,\n    generations=100,\n    mutation_rate=0.1,\n    random_state=42\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>population_size</code>: EA population size (default: 50) - <code>generations</code>: Number of generations (default: 100) - <code>mutation_rate</code>: Mutation probability (default: 0.1)</p> <p>Best for: Complex datasets, willing to trade speed for quality</p>"},{"location":"techniques/hybrid/#comparison","title":"Comparison","text":"<pre><code>from fairsample.utils import compare_techniques\n\nresults = compare_techniques(\n    X, y,\n    techniques=['SVDDWSMOTE', 'ODBOT', 'EHSO'],\n    complexity_measures='basic'\n)\n\nprint(results[['technique', 'N3', 'sample_size']])\n</code></pre>"},{"location":"techniques/hybrid/#next-steps","title":"Next Steps","text":"<ul> <li>Clustering-Based Methods</li> <li>Overlap-Based Methods</li> <li>API Reference</li> </ul>"},{"location":"techniques/overlap-based/","title":"Overlap-Based Undersampling","text":"<p>These techniques identify and remove overlapping instances from the majority class to reduce class overlap.</p>"},{"location":"techniques/overlap-based/#rfcl-random-forest-cleaning-rule","title":"RFCL - Random Forest Cleaning Rule","text":"<p>Uses Random Forest to identify and remove noisy majority class instances.</p> <pre><code>from fairsample import RFCL\n\nsampler = RFCL(\n    n_estimators=100,\n    max_depth=None,\n    random_state=42\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>n_estimators</code>: Number of trees (default: 100) - <code>max_depth</code>: Maximum tree depth (default: None) - <code>random_state</code>: Random seed</p> <p>Best for: General-purpose overlap reduction, fast execution</p>"},{"location":"techniques/overlap-based/#nus-neighbourhood-based-under-sampling","title":"NUS - Neighbourhood-based Under-Sampling","text":"<p>Removes majority instances based on local neighborhood analysis.</p> <pre><code>from fairsample import NUS\n\nsampler = NUS(\n    n_neighbors=5,\n    threshold=0.5\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>n_neighbors</code>: Number of neighbors to consider (default: 5) - <code>threshold</code>: Decision threshold (default: 0.5)</p> <p>Best for: Datasets with localized overlap regions</p>"},{"location":"techniques/overlap-based/#urns-undersampling-based-on-recursive-neighbourhood-search","title":"URNS - Undersampling based on Recursive Neighbourhood Search","text":"<p>Recursively identifies and removes overlapping instances.</p> <pre><code>from fairsample import URNS\n\nsampler = URNS(\n    n_neighbors=5,\n    max_iterations=10\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>n_neighbors</code>: Number of neighbors (default: 5) - <code>max_iterations</code>: Maximum recursion depth (default: 10)</p> <p>Best for: Complex overlap patterns, willing to trade speed for quality</p>"},{"location":"techniques/overlap-based/#deviocsvm-one-class-svm-method","title":"DeviOCSVM - One-Class SVM Method","text":"<p>Uses One-Class SVM to identify majority class outliers near the boundary.</p> <pre><code>from fairsample import DeviOCSVM\n\nsampler = DeviOCSVM(\n    nu=0.5,\n    kernel='rbf',\n    gamma='scale'\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>nu</code>: Upper bound on fraction of outliers (default: 0.5) - <code>kernel</code>: Kernel type (default: 'rbf') - <code>gamma</code>: Kernel coefficient (default: 'scale')</p> <p>Best for: Non-linear decision boundaries</p>"},{"location":"techniques/overlap-based/#fcmboostobu-fuzzy-c-means-boosted-overlap-based-undersampling","title":"FCMBoostOBU - Fuzzy C-Means Boosted Overlap-Based Undersampling","text":"<p>Uses fuzzy clustering to identify and remove overlapping instances.</p> <pre><code>from fairsample import FCMBoostOBU\n\nsampler = FCMBoostOBU(\n    n_clusters=3,\n    m=2.0,\n    max_iter=100\n)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre> <p>Parameters: - <code>n_clusters</code>: Number of fuzzy clusters (default: 3) - <code>m</code>: Fuzziness parameter (default: 2.0) - <code>max_iter</code>: Maximum iterations (default: 100)</p> <p>Best for: Datasets with fuzzy boundaries</p>"},{"location":"techniques/overlap-based/#comparison","title":"Comparison","text":"<pre><code>from fairsample.utils import compare_techniques\n\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS', 'DeviOCSVM', 'FCMBoostOBU'],\n    complexity_measures='basic'\n)\n\nprint(results[['technique', 'N3', 'F1', 'sample_size']])\n</code></pre>"},{"location":"techniques/overlap-based/#next-steps","title":"Next Steps","text":"<ul> <li>Hybrid Methods</li> <li>Clustering-Based Methods</li> <li>API Reference</li> </ul>"},{"location":"techniques/overview/","title":"Resampling Techniques Overview","text":"<p>This toolkit provides 14+ state-of-the-art resampling techniques for handling imbalanced datasets with class overlap.</p>"},{"location":"techniques/overview/#categories","title":"Categories","text":""},{"location":"techniques/overview/#overlap-based-undersampling","title":"Overlap-Based Undersampling","text":"<p>Focus on removing overlapping instances from the majority class.</p> <ul> <li>RFCL - Random Forest Cleaning Rule</li> <li>NUS - Neighbourhood-based Under-Sampling  </li> <li>URNS - Undersampling based on Recursive Neighbourhood Search</li> <li>DeviOCSVM - One-Class SVM method</li> <li>FCMBoostOBU - Fuzzy C-Means Boosted Overlap-Based Undersampling</li> </ul> <p>Learn more \u2192</p>"},{"location":"techniques/overview/#hybrid-methods","title":"Hybrid Methods","text":"<p>Combine undersampling and oversampling strategies.</p> <ul> <li>SVDDWSMOTE - SVDD-based overlap handler with SMOTE</li> <li>ODBOT - Outlier Detection-Based Oversampling Technique</li> <li>EHSO - Evolutionary Hybrid Sampling</li> </ul> <p>Learn more \u2192</p>"},{"location":"techniques/overview/#clustering-based","title":"Clustering-Based","text":"<p>Use clustering to identify and handle overlapping regions.</p> <ul> <li>NBUS - 4 variants (Centroid, Median, Nearest, Farthest)</li> <li>KMeansUndersampling - 4 variants (Centroid, Median, Nearest, Farthest)</li> </ul> <p>Learn more \u2192</p>"},{"location":"techniques/overview/#comprehensive","title":"Comprehensive","text":"<ul> <li>OSM - Overlap-Separating Model (handles multiple overlap types)</li> </ul>"},{"location":"techniques/overview/#baselines","title":"Baselines","text":"<ul> <li>RandomOverSampler - Random oversampling</li> <li>RandomUnderSampler - Random undersampling</li> </ul>"},{"location":"techniques/overview/#common-api","title":"Common API","text":"<p>All techniques follow scikit-learn's API:</p> <pre><code>from fairsample import RFCL\n\nsampler = RFCL(random_state=42)\nX_resampled, y_resampled = sampler.fit_resample(X, y)\n</code></pre>"},{"location":"techniques/overview/#choosing-a-technique","title":"Choosing a Technique","text":"<p>Use complexity measures to guide your choice:</p> <pre><code>from fairsample.utils import compare_techniques\n\nresults = compare_techniques(\n    X, y,\n    techniques=['RFCL', 'NUS', 'URNS', 'SVDDWSMOTE'],\n    complexity_measures='basic'\n)\n\n# Lower N3 = less overlap\nbest = results.sort_values('N3').iloc[0]\nprint(f\"Best technique: {best['technique']}\")\n</code></pre>"},{"location":"techniques/overview/#performance-considerations","title":"Performance Considerations","text":"Technique Speed Memory Best For RFCL Fast Low General overlap NUS Medium Low Local overlap URNS Slow Medium Complex overlap SVDDWSMOTE Slow High Small datasets NBUS Fast Low Large datasets KMeansUndersampling Fast Low Large datasets"},{"location":"techniques/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Overlap-Based Techniques</li> <li>Hybrid Methods</li> <li>Clustering-Based Methods</li> </ul>"}]}